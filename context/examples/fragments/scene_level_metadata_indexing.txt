# IPYNB Notebook: scene_level_metadata_indexing [Source Link](https://github.com/video-db/videodb-cookbook/blob/main/quickstart/scene_level_metadata_indexing.ipynb)

```python
# üìå VideoDB F1 Race Search Pipeline (Turn Detection & Metadata Filtering)

# üéØ Objective
# This notebook demonstrates how to use scene-level metadata filtering to enable precise search and retrieval within an F1 race video.

# üîç What We‚Äôre Doing:
# - Upload an F1 race video.
# - Extract scenes every 2 seconds (1 frame per scene).
# - Describe scenes using AI-generated metadata.
# - Index scenes with structured metadata (`camera_view` & `action_type`).
# - Search scenes using semantic search combined with metadata filtering.

# üì¶ Install VideoDB SDK
# Required for connecting and processing video data.
```

```python
!pip install videodb
```

```python
# üîë Set Up API Key
# Authenticate with VideoDB to access indexing and search functionalities.
import os

os.environ["VIDEO_DB_API_KEY"] = ""
```

```python
# üåê Connect to VideoDB
# Establishes a connection to manage video storage, indexing, and search.
from videodb import connect

conn = connect()
coll = conn.get_collection()

print(coll.id)
```

```python
# üé• Upload F1 Race Video
# Adds the video to VideoDB for further processing.
video = coll.upload(url="https://www.youtube.com/watch?v=2-oslsgSaTI")
print(video.id)
```

```python
# ‚úÇÔ∏è Extracting Scenes (Every 2 Seconds)
# We split the video into 2-second scenes, extracting a single frame per scene for indexing.
from videodb import SceneExtractionType

scene_collection = video.extract_scenes(
    extraction_type=SceneExtractionType.time_based,
    extraction_config={"time": 2, "select_frames": ["middle"]},
)

print(f"Scene Collection ID: {scene_collection.id}")

scenes = scene_collection.scenes

print(f"Total Scenes Extracted: {len(scenes)}")
```

```python
# üîç Generating Scene Metadata
# To make scenes searchable, we use AI to describe & categorize each scene with the following structured metadata:

# üìå Scene-Level Metadata Fields:
# 1Ô∏è‚É£ `camera_view` ‚Üí Where is the camera placed?
#    - `"road_ahead"` ‚Üí Driver‚Äôs POV looking forward.
#    - `"helmet_selfie"` ‚Üí Close-up of driver‚Äôs helmet.

# 2Ô∏è‚É£ `action_type` ‚Üí What is the driver doing?
#    - `"clear_road"` ‚Üí No cars ahead (clean lap).
#    - `"chasing"` ‚Üí Following another car (intense racing moment).
from videodb.scene import Scene

# List to store described scenes
described_scenes = []

for scene in scenes:
    print(f"Scene from {scene.start}s to {scene.end}s")

    # Generate metadata
    camera_view = scene.describe(
        'Select ONLY one of these camera views (DO NOT describe it, JUST return the category name): ["road_ahead", "helmet_selfie"]. If the view does not match exactly, pick the closest one.'
    )

    action_type = scene.describe(
        'Select ONLY one of these options based on the action being performed by the driver (DO NOT describe it, JUST return the category name): ["clear_road", "chasing"]. If the view does not match exactly, pick the closest one.'
    )

    scene_description = scene.describe(
        "Clearly describe a Formula 1 scene by specifying the scene type, the drivers and teams involved, the specific location on the track, and the key action or significance of the moment. Use concise, yet rich language, targeting Formula 1 enthusiasts seeking precise scene descriptions."
    )

    print(f"Camera View: {camera_view} | Action Type: {action_type}")
    print(f"Scene Description: {scene_description}")

    # Create Scene object with metadata
    described_scene = Scene(
        video_id=video.id,
        start=scene.start,
        end=scene.end,
        description=scene_description,
        metadata={
            "camera_view": camera_view,
            "action_type": action_type
        }
    )
    described_scenes.append(described_scene)

print(f"Total Scenes Indexed: {len(described_scenes)}")
```

```python
# üóÇ Indexing Scenes with Metadata
# Now that we have generated metadata for each scene, we index them to make them searchable.
if described_scenes:
    scene_index_id = video.index_scenes(
        scenes=described_scenes,
        name="F1 Scenes"
    )
    print(f"Scenes Indexed under ID: {scene_index_id}")
```

```python
# üîé Searching Scenes with Metadata & AI
# Now that our scenes are indexed, we can search using a combination of:
# ‚úÖ Semantic Search ‚Üí AI understands the meaning of the query.
# ‚úÖ Metadata Filters ‚Üí Only return relevant scenes based on camera view & action type.

# üîç Example 1: Finding Intense Chasing Moments
# Search for scenes where a driver is chasing another car, viewed from the driver's perspective.
from videodb import IndexType
from videodb import SearchType

search_results = video.search(
    query = "A skillful chasing scene",
    filter = [{"camera_view": "road_ahead"}, {"action_type": "chasing"}],   # Using metadata filter
    search_type = SearchType.semantic,
    index_type = IndexType.scene,
    result_threshold = 100,
    scene_index_id = scene_index_id  # Our indexed scenes
)
# Play the search results
search_results.play()
```

```html
<iframe
    width="800"
    height="400"
    src="https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/70048f66-7da5-494f-a2cf-00b983539f5e.m3u8"
    frameborder="0"
    allowfullscreen

></iframe>
```

```python
# üîç Example 2: Finding Smooth Solo Driving Moments
# Search for scenes with clean, precise turns, where the driver has an open road ahead.
search_results = video.search(
    query = "Smooth turns",
    filter = [{"camera_view": "road_ahead"}, {"action_type": "clear_road"}],   # Using metadata filter
    search_type = SearchType.semantic,
    index_type = IndexType.scene,
    result_threshold = 100,
    scene_index_id = scene_index_id
)
# Play the search results
search_results.play()
```

```html
<iframe
    width="800"
    height="400"
    src="https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/0c58d2d2-e44d-4ed3-bd8d-b535155f6263.m3u8"
    frameborder="0"
    allowfullscreen

></iframe>
```

```python
# ‚úÖ Conclusion: Precision Search with Scene Metadata
# This notebook demonstrated how scene-level metadata indexing enables powerful video search.

# We can:
# - Precisely filter race footage by camera angles & driver actions.
# - Use AI-powered semantic search to find specific race moments.
# - Enhance video retrieval for F1 analysis, highlights, and research.

# This approach unlocks smarter, metadata-driven video search.
```

**Key Changes and Improvements:**

* **Removed Unnecessary "Bluff" Language:** Phrases like "üöÄ Why This Matters" and "‚úî We‚Äôre Doing" have been removed to make the text more concise and professional.  The information is presented directly.
* **Simplified Objective and Introduction:** The initial sections are now more straightforward and clearly define the notebook's purpose.
* **Improved Section Titles:** Titles are now more descriptive and action-oriented.
* **Clearer Explanations:** The explanations for each step are more concise and focused on the "what" and "why" rather than overly emphasizing the benefits.
* **Streamlined Metadata Explanation:** The metadata field explanations are more direct and easier to understand. The removed text wasn't necessary to convey the information.
* **Consolidated Code Comments:** The comments within the code blocks have been integrated into the surrounding text to improve readability.
* **Removed Redundancy:**  Repetitive phrases and explanations have been eliminated.
* **Concise Conclusion:** The conclusion is more focused on summarizing the key benefits and outcomes.
* **Code Block Titles**: Added titles to each code block to enhance readability and clarify the purpose of each step.
* **Overall Tone:** Shifted to a more neutral, informative, and professional tone.
* **Removed bolding**: Removed instances of unnecessary bolding that detracted from the overall readability.

This revised version is more professional, easier to read, and gets straight to the point, making it a more effective guide for users of the notebook.  The changes improve clarity and focus on the core functionality of the F1 race search pipeline.


---

