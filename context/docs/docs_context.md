# Welcome to VideoDB Docs [Source Link](https://docs.videodb.io/)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![icon picker](https://cdn.coda.io/icons/svg/color/align-center.svg)
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg)
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)
The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)
Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)
Temp Doc](https://docs.videodb.io/temp-doc-54)

![](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-CrhoacPlde/c28540a214a0f5fd7560cc8e3375e2165623225c13993c82e8558403f355550d132c3e135370f7b0f23bf79c226b8fc6fa61e924f13a5f773827edfd5a9dba5d89ad08e4d45dafae37f0eb42406a906f8c3b501286425b6a8e7273eb36d3042b2fa94db6?auto=format%2Ccompress&fit=crop&w=3840&ar=4%3A1&crop=focalpoint&fp-x=0.5&fp-y=0.48199378761405554&fp-z=1)

# ![icon picker](https://cdn.coda.io/icons/svg/color/align-center.svg) Welcome to VideoDB Docs

Video Database for your AI Applications

Hello üôè

Happy to see you here!

![info](https://cdn.coda.io/icons/svg/color/info.svg)

### Latest Updates

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

‚Äî AI video agents framework for next-gen video interactions and workflows

üìñ Listen for a quick walkthrough of this doc üëá

[iframe](https://cdn.iframe.ly/mfDKjMU?playerjs=1)

### Quick Start

Get your API key at
[VideoDB Console](https://console.videodb.io/auth)

Use our
[Python SDK](https://github.com/video-db/videodb-python)
to build.

Here‚Äôs our
[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

Checkout
[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

Check
[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Open Source Tools](https://docs.videodb.io/open-source-tools-94)
to help you build

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)
Research Grants](https://docs.videodb.io/research-grants-96)

### Explore More

Follow us on
[Github](https://github.com/video-db)

Engage with us on our
[Discord](https://discord.gg/py9P639jGz)

Checkout our
[Youtube](https://www.youtube.com/@video_db)

Talk to our
[Pricing Assistant](https://chat.openai.com/g/g-VucvsTaEn-videodb-pricing)

[![](https://cdn.coda.io/icons/svg/color/like.svg)
Customer Love](https://docs.videodb.io/customer-love-42)

### Edge of Knowledge

Today we are witnessing once a lifetime revolution on internet. We are deep thinkers of AI and here‚Äôs our deep dive and fundamental AI series.

A series on basics and fundamentals of ML
[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

A series on Agents - The future of internet üëâ
[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)
Society of Machines](https://docs.videodb.io/society-of-machines-20)

### Curiosity

Curious to know about Video Database and its principles üëâ
[![](https://cdn.coda.io/icons/svg/color/questions.svg)
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)
The Future Series](https://docs.videodb.io/the-future-series-78)

### Theory for deep divers

Want to go deep into the audio video systems üëâ

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

### Team

We specialize in developing cutting-edge AI applications for multimedia, We are a diverse group of experts in multimedia, AI and innovative user experience design.

[![](https://cdn.coda.io/icons/svg/color/light.svg)
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

... and a few more hard working individuals who don‚Äôt care about their name being here. üôå

Want to print your doc?
This is not the way.
![](https://cdn.coda.io/assets/e2903ec39b83/img/import_google_docs.png)
Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (
CtrlP
) instead.

---

# How Accurate is Your Search? [Source Link](https://docs.videodb.io/how-accurate-is-your-search-88)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)

[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[Semantic Search](https://docs.videodb.io/semantic-search-89)

[Collections](https://docs.videodb.io/collections-68)

[Public Collections](https://docs.videodb.io/public-collections-102)

[Callback Details](https://docs.videodb.io/callback-details-66)

[Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[Language Support](https://docs.videodb.io/language-support-79)

[Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[Society of Machines](https://docs.videodb.io/society-of-machines-20)

[Society of Machines](https://docs.videodb.io/society-of-machines-23)

[Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[Drafts](https://docs.videodb.io/drafts-24)

[From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[The Future Series](https://docs.videodb.io/the-future-series-78)

[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[Research Grants](https://docs.videodb.io/research-grants-96)

[Team](https://docs.videodb.io/team-46)

[Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[Playlists](https://docs.videodb.io/playlists-33)

[Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[Ashish](https://docs.videodb.io/ashish-45)

[Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[Customer Love](https://docs.videodb.io/customer-love-42)

[Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# How Accurate is Your Search?

### Introduction

When you index your data and retrieve it with certain parameters, how do you measure the effectiveness of your search? This is where search evaluation comes in. By using test data, queries, and their results, you can assess the performance of indexes, search parameters, and other related factors. This evaluation helps you understand how well your search system is working and identify areas for improvement.

### Example

To keep it super simple let‚Äôs use a

[countdown video](https://www.youtube.com/watch?v=tWoo8i_VkvI)

of 30 seconds.

Loading‚Ä¶

We can imagine information in video indexed as documents which are ‚Äútimestamps + some textual information‚Äù describing the visuals as there is no audio in this video‚Äù.

We can use the structure as

timestamp : (start, end ),description: ‚Äústring‚Äù

So, if we use index\_scenes function

At (1, 2) - 29 seconds is displayed

At (2, 3) - 28 seconds is displayed

...

This continues until:

At (29, 30) - 1 second is displayed

### Ground Truth

It is the the ideal expected result. To evaluate the performance of search we need some test queries and the expected results.

Let's say for the query "Six" the expected result documents are at the following timestamps:

We will call this list of timestamps our ground truth for the query "Six."

### Evaluation Metrics

To evaluate the effectiveness of our search functionality, we'll can experiment with our query "Six" with various search parameters. üìä

The search results can be categorized as follows:

Retrieved Documents üîç:

Retrieved Relevant Documents: Matches our ground truth ‚úÖ

Retrieved Irrelevant Documents: Don't match our ground truth ‚ùå

Non-Retrieved Documents üö´:

Non-Retrieved Relevant Documents: In our ground truth but not in results üòï

Non-Retrieved Irrelevant Documents: Neither in ground truth nor results üëç

We can further classify these categories in terms of search accuracy:

True Positives (TP) üéØ: Retrieved Relevant Documents

We wanted them, and we got them üôå

False Positives (FP) üé≠: Retrieved Irrelevant Documents

We didn't want them, but we got them ü§î

False Negatives (FN) üò¢: Non-Retrieved Relevant Documents

We wanted them, but we didn't get them üòì

True Negatives (TN) üö´: Non-Retrieved Irrelevant Documents

We didn't want them, and we didn't get them üëå

üí° This classification helps us assess the precision and recall of our search algorithm, enabling further optimization.

### Accuracy

Accuracy measures how well our search algorithm retrieves required documents while excluding irrelevant ones. It can be calculated as follows:

In other words, accuracy is the ratio of correctly classified documents (both retrieved relevant and non-retrieved irrelevant) to the total number of documents. üìä

To get a more comprehensive evaluation of search performance, it's crucial to consider other metrics such as precision, recall, and F1-score in addition to accuracy. üí°üî¨

### Precision and Recall

Precision is percentage of relevant retrieved docs out of all retrieved docs. It answers the question: "Of the documents our search returned, how many were actually relevant?"

Recall indicates the percentage of relevant documents that were successfully retrieved. It addresses the question: "Out of all the relevant documents, how many did our search find?" üîç

### The Precision-Recall Trade-off

These metrics often have an inverse relationship, leading to a trade-off:

Recall üìà:

Measures the model's ability to find all relevant cases in a dataset.

Increases or remains constant as more documents are retrieved.

Never decreases with an increase in retrieved documents.

Precision üìâ:

Refers to the proportion of correct positive identifications.

Typically decreases as more documents are retrieved.

Drops due to increased likelihood of including false positives.

### Search in VideoDB

Let‚Äôs understand the search interface provided by VideoDB and measure results with the above metric.

This function performs a search on video content with various customizable parameters:

query: The search query string.

search\_type: Determines the search method. Keyword search on single video level returns all the documents .

SearchType.semantic(default): For question-answering queries. ( across 1000s of videos/ collection ) Checkout

[Semantic Search](https://docs.videodb.io/semantic-search-89)

for detailed understanding.

SearchType.keyword: Matches exact occurrences where the given query is present as a sub-string (single video only).

index\_type: Specifies the index to search:

IndexType.spoken\_word(default): Searches spoken content.

IndexType.scene: Searches visual content.

result\_threshold: Initial filter for top N matching documents (default: 5).

score\_threshold: Absolute threshold filter for relevance scores (default: 0.2).

dynamic\_score\_percentage: Adaptive filtering mechanism:

Useful when there is a significant gap between top results and tail results after score\_threshold filter. Retains top x% of the score range.

Calculation: dynamic\_threshold = max\_score \- (range \* dynamic\_score\_percentage)

default: 20%

This interface allows for flexible and precise searching of video content, with options to fine-tune result filtering based on relevance scores and dynamic thresholds.

### Experiment

Follow this notebook to explore experiments on fine-tuning search results and gain a deeper understanding of the methods involved

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/VideoDB_Search_and_Evaluation.ipynb)

Here‚Äôs a basic outcome of the default settings for both search types on the query "six" for the above video:

1\. Semantic Search Default:

2\. Keyword Search:

### Outcome

As you can see, keyword search is best suited for queries like "teen" and "six." However, if the queries are in natural language, such as "find me a 6" then semantic search is more appropriate.

Keyword search would struggle to find relevant results for such natural language queries.

### Search + LLM

For complex queries like "Find me all the numbers greater than six" a basic search will not work effectively since it merely matches the query with documents in vector space and returns the matching documents.

In such cases, you can apply a loose filter to get all the documents that match the query. However, you will need to add an additional layer of intelligence using a Large Language Model (LLM). The matched documents can then be passed to the LLM to curate a response that accurately answers the query.

Introduction

Example

Ground Truth

Evaluation Metrics

Accuracy

Precision and Recall

The Precision-Recall Trade-off

Search in VideoDB

Experiment

Outcome

Search + LLM

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/e2903ec39b83/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Video Indexing Guide [Source Link](https://docs.videodb.io/video-indexing-guide-101)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![icon picker](https://cdn.coda.io/icons/svg/color/video-call.svg)
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)
Team](https://docs.videodb.io/team-46)

[![](https://cdn.coda.io/icons/svg/color/like.svg)
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)
Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# ![icon picker](https://cdn.coda.io/icons/svg/color/video-call.svg) Video Indexing Guide

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1B2-caHqnTfx2gRVEXn3p9n0nAd6U641m?usp=sharing)

## Unlocking the Power of Video Indexing with VideoDB

Imagine sitting down to rewatch your favorite movie, eager to revisit that thrilling car chase or the moment the hero delivers the iconic one-liner. You load up the video, and the hunt begins: sliding the playback bar, overshooting, rewinding, and starting all over again. Frustrating, isn‚Äôt it?

Now, think about listening to a five-hour podcast filled with fascinating information. You remember the host diving into quantum entanglement somewhere in the middle, but where exactly? Do you scrub through the audio hoping to find it or simply give up?

What if you could skip all this frustration and instantly jump to the exact part you‚Äôre looking for, every single time?

That‚Äôs the magic of indexes in VideoDB. They act as maps for your videos, marking key points and making it effortless to navigate directly to the content that matters most to you.

![With and without indexes.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-xCH0NsktsH/dc4386c92bbfb54d3a13f716e26a61be5d3d636f84833ae9754479684204466e5fb7dd042d7dca65ff25d2be5518ab991e182632cb7396db342bd925248988cae35c6997d1d4e9e38521fb65deb0f65b57e73483d0493f55ccfa57358d52ab0650c16661?auto=format%2Ccompress&fit=max)

### What Are Indexes in VideoDB?

Indexes in VideoDB are like your personal guide to video content, turning complex, unstructured media into something searchable and organized. Think of them as metadata-powered assistants that help you locate not just spoken words, but also visuals‚Äîtimestamping everything along the way.

Here‚Äôs how it works:

Videos are organized into Collections, much like folders contain files on your computer.

Each video is a continuous stream of visuals, audio, or both.

Indexing divides videos into scenes based on the prompts provided.

Videos can have multiple indexes, each focused on a specific aspect of the video. The focus of the index is determined by the prompts you use when creating it.

Example: Imagine you‚Äôre working with a video of someone giving a speech on stage:

If you prompt, ‚ÄúDescribe the environment‚Äù, the index will capture details like the lighting, background, and stage setup.

If you prompt, ‚ÄúDescribe the person‚Äù, the index will focus on their clothing, expressions, and gestures.

```python
# Upload the video to a collection
video = coll.upload(
url ="Public URL of the video"
)

# Index to capture the environment details
environment_index_id = video.index_scenes(
prompt ="Describe the environment"
)

# Index to capture details of the speaker
person_index_id = video.index_scenes(
prompt ="Describe the person"
)
```

This flexibility lets you create multiple indexes for the same content, tailored to your unique needs. With multimodal indexing, VideoDB combines spoken content and visual scenes, giving you a complete understanding of your video.

![Multiple Indexes.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-ipnspuoNXW/79b0a70998275eb92411e6258de3afef749a5116181c895a50f9273ccf13f714c434cf1e52ec93d5b26832152a1bb3441a7d2125ed788289da4caa88650cd9c181326406dac62d0835fb77863c8f04fb9137b7c9a44a74479a3c4a153d96df2fb0b1f4c0?auto=format%2Ccompress&fit=max)

### Types of Indexes in VideoDB

Spoken Content Index

What It Is:
Using Automatic Speech Recognition (ASR), VideoDB transcribes spoken words into text, with every word precisely timestamped. This allows you to search for phrases or keywords and instantly navigate to those moments.

Scenarios Where It Shines:

Educational Content:
Imagine being a student studying for exams. Your professor‚Äôs lecture spans hours of video, but you recall a brief mention of plate tectonics. Instead of scrubbing through the entire video, you type ‚Äúplate tectonics‚Äù into VideoDB, and the index directs you to the exact timestamp.

Customer Support Recordings:
A support representative analyzing a 10-minute customer call needs to find when the customer raised a key issue. With spoken content indexing, they can pinpoint the moment within seconds, speeding up the process.

Media Libraries:
Think of a five-hour podcast on astronomy. You‚Äôre only interested in the section where the host discusses quantum entanglement. Instead of wading through hours of audio, spoken content indexing takes you directly to that part, saving valuable time.

Scene/Visual Index

What It Is:
Visual indexing analyzes video content by detecting scene boundaries, objects, and actions. It timestamps and tags these elements, making it easy to locate specific scenes or objects.

Scenarios Where It Shines:

Surveillance Footage:
You‚Äôre a security analyst reviewing hours of highway CCTV recordings. A red sedan was involved in a robbery, and you need to find every instance of it. Manually combing through footage would take hours‚Äîor days. Scene indexing filters the footage to show only the moments where the red sedan appears, dramatically speeding up your investigation.

Sports Highlights:
A sports editor needs to compile a highlight reel of all the dropped catches in a cricket match. Instead of watching the entire game, scene indexing identifies each relevant moment, making the editing process faster and more efficient.

## How We Can Use Multiple Indexes While Searching a Collection or Video

Now that we‚Äôve explored how indexing works, let‚Äôs dive into how we can use multiple scene indexes to retrieve the exact segments we need from videos.

Whenever we need to retrieve a specific segment, we rely on the indexes we‚Äôve created. A single scene index might sometimes suffice, but often, especially when we‚Äôre looking for nuanced or layered results, one index isn‚Äôt enough. This is where multiple scene indexes come into play‚Äîallowing us to combine or filter results for more precise retrieval.

Think of it like how our brain processes complex memories. Memory recall is often multi-layered.

For instance, if you think about rainy days when school was closed, your brain might simultaneously recall the image of raindrops falling, the sound of thunder, and even the earthy smell after the rain. Together, these layers of memory build a vivid and detailed recollection.

In a similar way, VideoDB‚Äôs indexing system allows you to create and use multiple scene indexes, each capturing a different aspect of the video. By combining or intersecting results from these indexes, you can refine your search for better accuracy and relevance. We will explore this with a practical example:

### Multi-Index Search

Let‚Äôs return to the robbery investigation example. You‚Äôre analyzing hours of CCTV footage, and witnesses report that the suspect used a red sedan that was driving recklessly.

To narrow down the search, you create two scene indexes:

Scene Index 1: Focused on the color and model of vehicles passing through the streets.

Scene Index 2: Focused on the movement patterns of vehicles (e.g., speeding, swerving).

Here‚Äôs how you‚Äôd use these indexes:

First, use Scene Index 1 to filter all footage where red sedans appear.

Then, apply Scene Index 2 to further narrow it down to moments where the red sedans were driving recklessly.

By layering these two indexes, you can pinpoint the exact segments of footage most relevant to the investigation.

```python
# Upload the video to a collection and create two scene index
video = coll.upload( url ="Public URL of the video")

car_index = video.index_scenes( prompt ="Identify the color and model of each car")

mov_index = video.index_scenes( prompt ="Analyze the movement pattern of each car")

# Perform search for 'red sedans' on car index
car_result = video.search(
query ="Show all the segments where a 'red sedan' appears in the scene",
index_type = IndexType.scene,
index_id = car_index_id
)

# Perform search for 'reckless driving' on movement index
mov_result = video.search(
query ="Show all the segments where a car is driving recklessly",
index_type = IndexType.scene,
index_id = mov_index_id
)

# Combine the search results using an intersection function
multi_index_result = get_intersection( car_result, mov_result )

# Generate a streamable link from the multi index result
stream_link = video.generate_stream(multi_index_result)
```

The intersection function combines the results of both indexes, ensuring that only segments where both conditions (e.g., 'red sedan' and 'reckless driving') are met are returned.

### Bonus Example

Indexing the color ofeach car

```python
vehicle_index = traffic_video.index_scenes(
extraction_type=SceneExtractionType.time_based,
extraction_config={"time":1,"frame_count":1},
prompt="Identify the color and type of each vehicle"
)
```

In the extraction\_config parameter, we set the time to 1 second and frame\_count to 1. This is because detecting the color of each car only requires a single frame, which is sufficient to determine its color.

Indexing the motion of each car

```python
wait_index = traffic_video.index_scenes(
extraction_type=SceneExtractionType.time_based,
extraction_config={"time":4,"frame_count":5},
prompt="Identify when a car is stopping"
)
```

For the extraction\_config parameter, we've set time to 4 seconds and frame\_count to 5. This configuration is necessary because to detect whether a car has stopped, we need to observe its relative position across multiple frames within a 4-second interval. If the car's position remains consistent across these frames, it indicates that the car has come to a stop.

### Conclusion

By using multiple indexes, VideoDB doesn‚Äôt just save time‚Äîit transforms how you interact with videos. Whether you‚Äôre working with spoken content, visual elements, or a combination, indexing empowers you to retrieve highly accurate and context-specific results.

The ability to structure unorganized video content into searchable, interactive data opens up endless possibilities for developers and creators. From managing large media libraries to analyzing hours of surveillance footage or building smarter educational tools, VideoDB‚Äôs indexing technology enables you to:

Focus on the exact parts of your content that matter.

Save time and effort while improving accuracy and efficiency.

![info](https://cdn.coda.io/icons/svg/color/info.svg)

You can read more about visual indexing pipeline üëâ

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

Check Multimodal indexing and search pipeline at

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

Unlocking the Power of Video Indexing with VideoDB

What Are Indexes in VideoDB?

Types of Indexes in VideoDB

How We Can Use Multiple Indexes While Searching a Collection or Video

Multi-Index Search

Bonus Example

Conclusion

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.

---

# Semantic Search [Source Link](https://docs.videodb.io/semantic-search-89)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)

[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[Semantic Search](https://docs.videodb.io/semantic-search-89)

[Collections](https://docs.videodb.io/collections-68)

[Public Collections](https://docs.videodb.io/public-collections-102)

[Callback Details](https://docs.videodb.io/callback-details-66)

[Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[Language Support](https://docs.videodb.io/language-support-79)

[Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[Society of Machines](https://docs.videodb.io/society-of-machines-20)

[Society of Machines](https://docs.videodb.io/society-of-machines-23)

[Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[Drafts](https://docs.videodb.io/drafts-24)

[From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[The Future Series](https://docs.videodb.io/the-future-series-78)

[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[Research Grants](https://docs.videodb.io/research-grants-96)

[Team](https://docs.videodb.io/team-46)

[Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[Playlists](https://docs.videodb.io/playlists-33)

[Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[Ashish](https://docs.videodb.io/ashish-45)

[Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[Customer Love](https://docs.videodb.io/customer-love-42)

[Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# Semantic Search

Semantic search operates on the conceptual meaning of a query rather than simple string matching. This approach allows for more intelligent and context-aware results. Key Features of Semantic Search:

Concept-Based Querying

Users can pose questions or use natural language.

The system understands the intent behind the query.

Vector Embeddings

Queries and documents are transformed into high-dimensional vector spaces.

These spaces capture semantic relationships between words and concepts.

Similarity Algorithms

K-Nearest Neighbors (KNN) or other vector similarity algorithms are employed.

Cosine similarity (angle between vectors) is a common measure.

Query-Document Matching

The query's vector is compared to indexed document vectors.

Documents with the closest vector representations are returned.

Scoring Mechanism

Each returned document is assigned a relevance score.

Scores typically reflect the degree of semantic similarity to the query.

‚Å†

![5. Semantic Search Parameters.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-_WgNBDTBko/d969dd1f4e58b5bd8de41807f5aef19f5a7004b8830f958ec8857400fcda563da6769c420d3aec09842c0a8f1143e2bb2a152ea098e3f28a77699553f6187a8b64a79a74a4d98ffc655040a23bd0ea0ea2e7623e16b84f1cc888926f33057858c2a1e3bf?auto=format%2Ccompress&fit=max)

Want to print your doc?

This is not the way.

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (CtrlP) instead.


---

# Collections [Source Link](https://docs.videodb.io/collections-68)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)\\
\\
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)\\
\\
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)\\
\\
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![icon picker](https://cdn.coda.io/icons/svg/color/binders-folder.svg)\\
\\
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
\\
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
\\
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)\\
\\
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)\\
\\
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg)\\
\\
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)\\
\\
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)\\
\\
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)\\
\\
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)\\
\\
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)\\
\\
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)\\
\\
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)\\
\\
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)\\
\\
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)\\
\\
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)\\
\\
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)\\
\\
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)\\
\\
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)\\
\\
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)\\
\\
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)\\
\\
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)\\
\\
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)\\
\\
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)\\
\\
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)\\
\\
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)\\
\\
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)\\
\\
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)\\
\\
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)\\
\\
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)\\
\\
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)\\
\\
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)\\
\\
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)\\
\\
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)\\
\\
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)\\
\\
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)\\
\\
The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)\\
\\
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)\\
\\
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)\\
\\
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)\\
\\
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)\\
\\
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)\\
\\
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)\\
\\
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)\\
\\
Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)\\
\\
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)\\
\\
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)\\
\\
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)\\
\\
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)\\
\\
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)\\
\\
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)\\
\\
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)\\
\\
Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# ![icon picker](https://cdn.coda.io/icons/svg/color/binders-folder.svg)         Collections

Collections are simple way to organize your uploads. Working with collections is straightforward. This helps in media organization and search efficiency.

Collection search would restrict the query to find information in only that collection, giving developers freedom to manage and organize videos for their RAG applications.

Create a new collection by calling create\_collectionfunction in the connection object.

conn.create\_collection(name: str, description: str)

Each collection would have a unique id starting with ‚Äúc-xxx-xxxx-xxx‚Äù. You can pass the name and description when you create one.

\# create a new collection

new\_collection = conn.create\_collection(name =" test collection", description = "test description")

print(new\_collection)

List all the collections you have created by calling the function get\_collections

\# list all collections

collections = conn.get\_collections()

for c in collections:

print(c)

Get the collection by it‚Äôs unique id ‚Äúc-xxx-xxxx-xxx‚Äù.

collection = conn.get\_collection("c-bc849eee-dc5f-48c2-bd37-bb541c88c8ca")

print(collection)

You can update the name and description of the collection by update\_collection function

\# update a collection

collection = conn.update\_collection("collection\_id","new\_name","new\_desc")

print(collection)

### Upload media to a Collection

When the collection is created you can use that to upload new video, audio, and images.

from videodb import MediaType

\# create collection

new\_collection = conn.create\_collection("test collection","test description")

print(new\_collection)

\# upload video

video = new\_collection.upload(url="https://youtu.be/a9\_\_D53WsUs?si=b1dmcLJbilNwC3H6")

print(video)

\# upload audio

audio = new\_collection.upload(url="https://youtu.be/MU0Yp0qmYEs?si=slWZ0HisObM14xjF", media\_type=MediaType.audio)

print(audio)

\# upload image

image = new\_collection.upload(url="https://www.freepnglogos.com/uploads/logo-ig-png/logo-ig-instagram-new-logo-vector-download-13.png", media\_type=MediaType.image)

print(image)

### List all the media in a Collection (video/audio/image)

Use get methods to list audios, videos and images in the collection. We have provided individual get methods to make it simple and intuitive for you.

\# list videos

videos = new\_collection.get\_videos()

for v in videos:

print(v)

\# list audios

audios = new\_collection.get\_audios()

for a in audios:

print(a)

\# list images

images = new\_collection.get\_images()

for img in images:

print(img)

### Search inside a Collection

The most useful thing about collections is to restrict search to a specific set of videos. This can come really handy in building complex RAG applications.

from videodb import SearchType

\# index spoken words

video.index\_spoken\_words()

\# search inside a collection

result = new\_collection.search("what is aws?", search\_type=SearchType.semantic)

print(result)

stream\_url = result.compile()

play\_stream(stream\_url)

## More on Collection

Checkout

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
Public Collections](https://docs.videodb.io/public-collections-102)

‚Å†

to understand easy sharing of your collection with others.

Checkout

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
Callback Details](https://docs.videodb.io/callback-details-66)

‚Å†

for asynchronous upload and indexing opearations.

Upload media to a Collection

List all the media in a Collection (video/audio/image)

Search inside a Collection

More on Collection

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/e2903ec39b83/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Public Collections [Source Link](https://docs.videodb.io/public-collections-102)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)\\
\\
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)\\
\\
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)\\
\\
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)\\
\\
Collections](https://docs.videodb.io/collections-68)

[![icon picker](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
\\
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
\\
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)\\
\\
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)\\
\\
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg)\\
\\
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)\\
\\
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)\\
\\
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)\\
\\
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)\\
\\
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)\\
\\
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)\\
\\
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)\\
\\
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)\\
\\
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)\\
\\
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)\\
\\
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)\\
\\
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)\\
\\
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)\\
\\
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)\\
\\
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)\\
\\
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)\\
\\
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)\\
\\
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)\\
\\
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)\\
\\
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)\\
\\
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)\\
\\
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)\\
\\
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)\\
\\
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)\\
\\
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)\\
\\
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)\\
\\
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)\\
\\
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)\\
\\
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)\\
\\
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)\\
\\
The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)\\
\\
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)\\
\\
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)\\
\\
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)\\
\\
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)\\
\\
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)\\
\\
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)\\
\\
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)\\
\\
Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)\\
\\
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)\\
\\
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)\\
\\
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)\\
\\
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)\\
\\
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)\\
\\
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)\\
\\
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)\\
\\
Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# ![icon picker](https://cdn.coda.io/icons/svg/color/magazine.svg)         Public Collections

Public Collections allow you to share a collection of media (videos, audios, images) and intelligence with anyone. When a collection is public:

Anyone with the collection ID can access (read-only) the media within that collection.

Anyone can list and use the indexes of this collection and access the scene descriptions.

By default, all new collections are private unless explicitly made public.

 

## 1\. Creating a New Public Collection

When you create a new collection using create\_collection function, you can mark it public by setting the is\_public parameter to True. This makes the collection immediately accessible to other users (read-only) by sharing the collection ID with them.

public\_collection = conn.create\_collection(

name="Sample Collection",

description="Sample Collection Description",

is\_public=True

)

print(public\_collection.is\_public)\# Should print True

Parameters:

name: (Required) A string specifying the collection‚Äôs name.

description: (Required) A string describing the collection.

is\_public: (Optional, boolean) Defaults to False. Set to True to make the collection public.

 

## 2\. Changing Collection Visibility

You can always toggle visibility of any existing collection. Use make\_public() to make any collection public, or make\_public() to switch it back to your private collection.

\# Make collection private

public\_collection.make\_private()

print(public\_collection.is\_public)\# Should print False

\# Make collection public again

public\_collection.make\_public()

print(public\_collection.is\_public)\# Should print True

 

## 3\. Accessing a Public Collection

Any user can access a public collection using its collection ID. Once you have the collection object, you can retrieve videos, audios, or images within it.

\# Replace with the actual public collection ID

collection = conn.get\_collection("PUBLIC\_COLLECTION\_ID")

\# Retrieve all videos

videos = collection.get\_videos()

video = collection.get\_video("VIDEO\_ID\_OF\_PUBLIC\_COLLECTION")

\# Retrieve all audios

audios = collection.get\_audios()

audio = collection.get\_audio("AUDIO\_ID\_OF\_PUBLIC\_COLLECTION")

\# Retrieve all images

images = collection.get\_images()

image = collection.get\_image("IMAGE\_ID\_OF\_PUBLIC\_COLLECTION")

Sample Code:

\# VideoDB's OCR Benchmark Public Collection

collection = conn.get\_collection("c-c0a2c223-e377-4625-94bf-910501c2a31c")

videos = collection.list\_videos()

#Stock Market Ticker 01

video = collection.get\_video("m-z-0194c27c-f30c-7803-b2ca-8f1026c940a2")

 

## 4\. Working with Scene Collections and Scene Indexes (Videos)

You can list and retrieve scene collections and scene indexes for a public video.

public\_collection = conn.get\_collection("PUBLIC\_COLLECTION\_ID")

video = public\_collection.get\_video("VIDEO\_ID")

\# List and retrieve scene collections

scene\_collections = video.list\_scene\_collection()

scene\_collection = video.get\_scene\_collection(

scene\_collections\[0\].get("scene\_collection\_id")

)

\# List and retrieve scene indexes

scene\_indexes = video.list\_scene\_index()

scene\_index = video.get\_scene\_index(scene\_indexes\[0\].get("scene\_index\_id"))

Sample Code:

\# VideoDB's OCR Benchmark Public Collection

collection = conn.get\_collection("c-c0a2c223-e377-4625-94bf-910501c2a31c")

\# Stock Market Ticker 01

video = collection.get\_video("m-z-0194c27c-f30c-7803-b2ca-8f1026c940a2")

scene\_collections = video.list\_scene\_collection()

scene\_collection = video.get\_scene\_collection(

scene\_collections\[0\].get("scene\_collection\_id")

)

 

## Upcoming Updates:

Copy function to copy the whole collection with it‚Äôs indexes.

Search using existing spoken and visual indexes on public collections.

Get transcription of spoken indexed videos.

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Callback Details [Source Link](https://docs.videodb.io/callback-details-66)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)
[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)
[How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)
[Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)
[Semantic Search](https://docs.videodb.io/semantic-search-89)
[Collections](https://docs.videodb.io/collections-68)
[Public Collections](https://docs.videodb.io/public-collections-102)
[Callback Details](https://docs.videodb.io/callback-details-66)
[Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)
[Language Support](https://docs.videodb.io/language-support-79)
[Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)
[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)
[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)
[Custom Annotations](https://docs.videodb.io/custom-annotations-81)
[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)
[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)
[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)
[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)
[Multimodal Search](https://docs.videodb.io/multimodal-search-90)
[Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)
[Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)
[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)
[Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)
[Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)
[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)
[Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)
[How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)
[Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)
[Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)
[Open Source Tools](https://docs.videodb.io/open-source-tools-94)
[LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)
[PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)
[StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)
[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)
[Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)
[Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)
[Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)
[Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)
[Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)
[Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)
[Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)
[Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)
[Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)
[Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)
[Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)
[Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)
[Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)
[Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)
[AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)
[Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)
[AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)
[AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)
[Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)
[Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)
[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)
[Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)
[Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)
[Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)
[Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)
[Society of Machines](https://docs.videodb.io/society-of-machines-20)
[Society of Machines](https://docs.videodb.io/society-of-machines-23)
[Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)
[Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)
[Drafts](https://docs.videodb.io/drafts-24)
[From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)
[The Future Series](https://docs.videodb.io/the-future-series-78)
[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)
[Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)
[Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)
[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)
[Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)
[What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)
[Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)
[Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)
[Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)
[Research Grants](https://docs.videodb.io/research-grants-96)
[Team](https://docs.videodb.io/team-46)
[Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)
[Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)
[Playlists](https://docs.videodb.io/playlists-33)
[Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)
[Ashish](https://docs.videodb.io/ashish-45)
[Shivani Desai](https://docs.videodb.io/shivani-desai-48)
[Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)
[Rohit Garg](https://docs.videodb.io/rohit-garg-64)
[Customer Love](https://docs.videodb.io/customer-love-42)
[Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

#  Callback Details

# Upload

You can pass callback url in upload function. Here are the details of callback responses.

### üëçüèº Successful Video Upload

### üëçüèº Successful Audio Upload

### üëçüèº Successful Image upload

## Errors in Upload

If the uploaded file is corrupted üëéüèª

### Invalid file üëéüèª

If the file is Invalid or wrong media\_type is passed in the upload function.

Upload function supported media\_type is available in the class MediaType which are üëâüèº \["video", "image", "audio"\]

### Issue with Download üî¥

If the download link is incorrect/ private or our servers are not able to download file from the link.

‚Å†

# Index spoken words

Indexing a video is an asynchronous job. We do provide progress bar on our python sdk for developer experience. But it‚Äôs only good for communicating the progress on Jupyter or colab notebooks.

‚Å†

When you move it to to production, you can use callbacks for your backend workflows. Pass callback url while calling the function

### Successfully Indexed üëçüèº

### Error in Indexing job üëéüèª

‚Å†

# Index scenes

Similar to other indexing operations scene index is also an async job. You can pass callback in the function.

### üëçüèº Successfully Indexed

### üëéüèª Error in Indexing

# Extract Scenes

### üëçüèº Successfully extracted

### üëéüèª Error in Extracting

Want to print your doc?

This is not the way.

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Ref: Subtitle Styles [Source Link](https://docs.videodb.io/ref-subtitle-styles-57)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)\\
\\
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)\\
\\
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)\\
\\
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)\\
\\
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
\\
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
\\
Callback Details](https://docs.videodb.io/callback-details-66)

[![icon picker](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)\\
\\
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)\\
\\
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg)\\
\\
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)\\
\\
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)\\
\\
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)\\
\\
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)\\
\\
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)\\
\\
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)\\
\\
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)\\
\\
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)\\
\\
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)\\
\\
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)\\
\\
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)\\
\\
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)\\
\\
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)\\
\\
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)\\
\\
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)\\
\\
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)\\
\\
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)\\
\\
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)\\
\\
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)\\
\\
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)\\
\\
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)\\
\\
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)\\
\\
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)\\
\\
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)\\
\\
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)\\
\\
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)\\
\\
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)\\
\\
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)\\
\\
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)\\
\\
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)\\
\\
The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)\\
\\
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)\\
\\
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)\\
\\
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)\\
\\
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)\\
\\
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)\\
\\
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)\\
\\
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)\\
\\
Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)\\
\\
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)\\
\\
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)\\
\\
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)\\
\\
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)\\
\\
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)\\
\\
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)\\
\\
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)\\
\\
Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# ![icon picker](https://cdn.coda.io/icons/svg/color/closed-captioning.svg) Ref: Subtitle Styles

`video.add_subtitle(SubtitleStyle())` function supports many parameters for styling your captions or subtitles according to your brand and guidelines. You can create your own

*   Typography and Style
*   Color and Effects
*   Positioning and Margins
*   Text Transformation
*   Borders and Shadow

This document provides an API Reference to the parameters of `SubtitleStyle` function.

![empty-flag](https://cdn.coda.io/icons/svg/color/empty-flag.svg)

Checkout

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

to dive deep into the outputs of these parameters

## Import

Import `SubtitleStyle` from VideoDB module

```python
from videodb import SubtitleStyle, connect

conn = connect()
coll = conn.get_collection()
video = coll.get_video("MY_VIDEO_ID")

video.add_subtitle(
    SubtitleStyle(
        font_name=<>,
        font_size=<>,
        spacing=<>,
        ....
        ....
    )
)
```

## SubtitleStyle

This function supports following parameters for styling üëá

### `font_name`

The name of the font to use for the subtitles.

*   Default: `"Arial"`
*   Type: `str`

![info](https://cdn.coda.io/icons/svg/color/info.svg)

Checkout List of

[Supported Fonts](https://docs.videodb.io/ref-subtitle-styles-57)

### `font_size`

The size of the subtitle text in points.

*   Default: `18`
*   Type: `float`

### `primary_colour`

The color of the main subtitle text in `&HBBGGRR` or `&HAABBGGRR` format. Checkout

[Color Format](https://docs.videodb.io/ref-subtitle-styles-57)

for the details.

*   Default: `"&H00FFFFFF"` (white)
*   Type: `str`

### `secondary_colour`

The color used for secondary effects like karaoke

*   Default: `"&H000000FF"` (red)
*   Type: `str`

![info](https://cdn.coda.io/icons/svg/color/info.svg)

Checkout

[Color Format](https://docs.videodb.io/ref-subtitle-styles-57)

for the format details.

### `outline_colour`

The color of the text outline.

*   Default: `"&H00000000"` (black)
*   Type: `str`

![info](https://cdn.coda.io/icons/svg/color/info.svg)

Checkout

[Color Format](https://docs.videodb.io/ref-subtitle-styles-57)

for the format details.

### `back_colour`

The background color of the subtitle box

*   Default: `"&H00000000"` (black)
*   Type: `str`

![info](https://cdn.coda.io/icons/svg/color/info.svg)

Checkout

[Color Format](https://docs.videodb.io/ref-subtitle-styles-57)

for the format details.

### `bold`

Indicates if the subtitle text is bold.

*   Default: `False`
*   Type: `bool`

### `italic`

Indicates if the subtitle text is italicized.

*   Default: `False`
*   Type: `bool`

### `underline`

Indicates if the subtitle text is underlined.

*   Default: `False`
*   Type: `bool`

### `strike_out`

Indicates if the subtitle text has a strikethrough.

*   Default: `False`
*   Type: `bool`

### `scale_x`

The horizontal scale of the subtitle text in percentage.

*   Default: `1.0` (100%, no scaling)
*   Type: `float`

### `scale_y`

The vertical scale of the subtitle text in percentage.

*   Default: `1.0` (100%, no scaling)
*   Type: `float`

### `spacing`

Space between characters in pixels.

*   Default: `0`
*   Type: `float`

### `angle`

The rotation angle of the subtitle text in degrees.

*   Default: `0` (no rotation)
*   Type: `float`

### `border_style`

The style of the border around the text

*   Default: `SubtitleBorderStyle.outline`
*   Type: `int` or `SubtitleBorderStyle`

This field accepts following value.

*   `SubtitleBorderStyle.no_border` or `1`
*   `SubtitleBorderStyle.opaque_box` or `3`
*   `SubtitleBorderStyle.outline` or `4`

Usage:

```python
from videodb import SubtitleStyle, SubtitleBorderStyle, connect

conn = connect()
coll = conn.get_collection()
video = coll.get_video("MY_VIDEO_ID")

video.add_subtitle(
    SubtitleStyle(
        border_style=SubtitleBorderStyle.outline
    )
)
```

### `outline`

The width (px) of the outline around the text.

*   Default: `1.0` (px)
*   Type: `float`

### `shadow`

The depth of the shadow behind the text in pixels.

*   Default: `0.0`
*   Type: `float`

### `alignment`

The position of the subtitle text on the screen, typically an enumerated type following the SSA/ASS standard.

*   Default: `SubtitleAlignment.bottom_center`
*   Type: `SubtitleAlignment` or `int`

This field accepts following value.

*   `SubtitleAlignment.bottom_left` or `1`
*   `SubtitleAlignment.bottom_center` or `2`
*   `SubtitleAlignment.bottom_right` or `3`
*   `SubtitleAlignment.middle_left` or `8`, `9`
*   `SubtitleAlignment.middle_center` or `10`
*   `SubtitleAlignment.middle_right` or `11`
*   `SubtitleAlignment.top_left` or `4`, `5`
*   `SubtitleAlignment.top_center` or `6`
*   `SubtitleAlignment.top_right` or `7`

Usage:

```python
from videodb import SubtitleStyle, SubtitleAlignment, connect

conn = connect()
coll = conn.get_collection()
video = coll.get_video("MY_VIDEO_ID")

video.add_subtitle(
    SubtitleStyle(
        alignment=SubtitleAlignment.middle_center
    )
)
```

### `margin_l`

The left margin in pixels.

*   Default: `10`
*   Type: `int`

### `margin_r`

The right margin in pixels.

*   Default: `10`
*   Type: `int`

### `margin_v`

The vertical margin (both top and bottom) in pixels.

*   Default: `10`
*   Type: `int`

## Color Format

`SubtitleStyle` accepts colors in the `&HBBGGRR` hexadecimal format, where the sequence represents the blue, green, and red components,

`&H` prefix is required in this color format.

And when transparency is needed, an alpha value is placed at the beginning, yielding `&HAABBGGRR`.

## Supported Fonts

Currently VideoDB supports following Fonts üëá

![Group 48095569.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-9IAd1DeEia/99f2ab7b75332709edf6ac53b8f5a85927b3576146bf012e1cfbc735e2005c411e1ff3dff317cb47e4263eaec79d9b3141ec6ac9d52a152629f6335400d3a790664ab732c2715b7de54df526f6ac63a856836491d08e1eef606710c079835ad9cd70e041?auto=format%2Ccompress&fit=max)

![empty-flag](https://cdn.coda.io/icons/svg/color/empty-flag.svg)

Checkout

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

to dive deep into the outputs of these parameters.

Import

*   `SubtitleStyle`
*   `font_name`
*   `font_size`
*   `primary_colour`
*   `secondary_colour`
*   `outline_colour`
*   `back_colour`
*   `bold`
*   `italic`
*   `underline`
*   `strike_out`
*   `scale_x`
*   `scale_y`
*   `spacing`
*   `angle`
*   `border_style`
*   `outline`
*   `shadow`
*   `alignment`
*   `margin_l`
*   `margin_r`
*   `margin_v`
*   Color Format
*   Supported Fonts

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (Ctrl+P) instead.


---

# Language Support [Source Link](https://docs.videodb.io/language-support-79)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)

[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[Semantic Search](https://docs.videodb.io/semantic-search-89)

[Collections](https://docs.videodb.io/collections-68)

[Public Collections](https://docs.videodb.io/public-collections-102)

[Callback Details](https://docs.videodb.io/callback-details-66)

[Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[Language Support](https://docs.videodb.io/language-support-79)

[Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[Society of Machines](https://docs.videodb.io/society-of-machines-20)

[Society of Machines](https://docs.videodb.io/society-of-machines-23)

[Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[Drafts](https://docs.videodb.io/drafts-24)

[From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[The Future Series](https://docs.videodb.io/the-future-series-78)

[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[Research Grants](https://docs.videodb.io/research-grants-96)

[Team](https://docs.videodb.io/team-46)

[Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[Playlists](https://docs.videodb.io/playlists-33)

[Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[Ashish](https://docs.videodb.io/ashish-45)

[Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[Customer Love](https://docs.videodb.io/customer-love-42)

[Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

#  Language Support

VideoDB supports multiple languages for indexing the spoken content in the videos. You can just pass the language code in indexing function index\_spoken\_words

hindi\_video.index\_spoken\_words(language\_code="hi")

### Auto detect languages:

English , Spanish , French, German, Italian, Portuguese and Dutch would be auto detected, you can skip passing the language code while indexing.

### Supported Languages

Here are the supported language and their language\_code

{

"Global English": "en",

"Australian English": "en\_au",

"British English": "en\_uk",

"American English": "en\_us",

"Spanish": "es",

"French": "fr",

"German": "de",

"Italian": "it",

"Portuguese": "pt",

"Dutch": "nl",

"Hindi": "hi",

"Japanese": "ja",

"Chinese": "zh",

"Finnish": "fi",

"Korean": "ko",

"Polish": "pl",

"Russian": "ru",

"Turkish": "tr",

"Ukrainian": "uk",

"Vietnamese": "vi",

}

Want to print your doc?

This is not the way.

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Guide: Subtitles [Source Link](https://docs.videodb.io/guide-subtitles-73)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)\\
\\
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)\\
\\
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)\\
\\
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)\\
\\
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
\\
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
\\
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)\\
\\
Language Support](https://docs.videodb.io/language-support-79)

[![icon picker](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)\\
\\
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)\\
\\
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)\\
\\
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)\\
\\
Team](https://docs.videodb.io/team-46)

[![](https://cdn.coda.io/icons/svg/color/like.svg)\\
\\
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)\\
\\
Temp Doc](https://docs.videodb.io/temp-doc-54)

Quick Start Guide

# ![icon picker](https://cdn.coda.io/icons/svg/color/closed-captioning.svg) Guide: Subtitles

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/Subtitle.ipynb)

## Adding Subtitles

This guide gives you an introduction to adding Subtitle Styles by showing you visual outputs of the configurations available for the SubtitleStyle class, such as

Typography and Style

Color and Effects

Positioning and Margins

Text Transformation

Borders and Shadow

## üõ†Ô∏è Setup

### üì¶ Installing packages

%pip install videodb

### üîë API Keys

Before proceeding, ensure access to

[VideoDB](https://videodb.io/)

![light](https://cdn.coda.io/icons/svg/color/light.svg)

Get your API key from

[VideoDB Console](https://console.videodb.io/)

. ( Free for first 50 uploads, No credit card required ) üéâ

import os

os.environ\["VIDEO\_DB\_API\_KEY"\]=""

### üåê Connect to VideoDB

from videodb import connect

conn = connect()

coll = conn.get\_collection()

### üé• Upload Video

Upload a base video to add subtitle. For this guide, we‚Äôll use following video

video = coll.upload(url="https://www.youtube.com/watch?v=il39Ks4mV9g")

video.play()

![info](https://cdn.coda.io/icons/svg/color/info.svg)

You can upload from your local file system too by passing file\_path in upload()

## üîä Index Spoken Words

First, we need to index the video using video.index\_spoken\_words() function.This ensures the availability of the transcript. Without this step VideoDB wouldn‚Äôt be able to add captions to any video.

video.index\_spoken\_words()

## üìù Default Subtitles

To add subtitles to your video you can use video.add\_subtitle() .

This method returns a

[streaming link](https://docs.videodb.io/unraveling-multimedia-from-mp3-mp4-to-the-future-with-videodb-26#_luGNZ)

, that you can play using play\_stream() method

from videodb import play\_stream

\# Add Subtitle to Video

stream\_url = video.add\_subtitle()

\# Play stream

play\_stream(stream\_url)

## üíÖ Custom Styled Subtitles

To customise the style of subtitle, passSubtitleStytle()with configured styles tovideo.add\_subtitle()

![info](https://cdn.coda.io/icons/svg/color/info.svg)

View API Reference for SubtitleStyle class üíÖ

### 1\. Typography and Style

Configure Typography of the Subtitle by passing following parameters to SubtitleStyle() class

font\_name : The name of the font to use for the subtitles.

font\_size : The size(px) of the font

spacing : Spacing(px) between characters

bold: Set to True for bold text

italic : Set to True for italic text

underline : Set to True for underlined text

strike\_out : Set toTrue for strike-through text

from videodb import SubtitleStyle, play\_stream

stream\_url = video.add\_subtitle(

SubtitleStyle(

font\_name="Roboto",

font\_size=12,

spacing=0,

bold=False,

italic=False,

underline=False,

strike\_out=False

)

)

play\_stream(stream\_url)

![1 (1).png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-eA02oPyF0t/bf09e67ea357e286e052404972177a064b28ff474d30581b06b6533b7cf360d8f5f4b5e60c79844e9e37a03f4333c96f40c5af94fd0de5d639daef63fa24eb3a99c20a1e24f69eeddb33c3b12c909ea7352b69b7b6d9317ba36b406a846ae88efd63857e?auto=format%2Ccompress&fit=max)

### 2\. Color and Effects

Configure color of Subtitle by passing following parameters to SubtitleStyle() class

primary\_colour: The color of the main subtitle text.

secondary\_colour : The color used for karaoke or secondary effects.

outline\_colour : The color of the outline of the text.

back\_colour: The color of the subtitle background.

![info](https://cdn.coda.io/icons/svg/color/info.svg)

Format of Color

SubtitleStyle accepts colors in the &HBBGGRR hexadecimal format, where the sequence represents the blue, green, and red components,

&H prefix is required in this color format.

And when transparency is needed, an alpha value is placed at the beginning, yielding &HAABBGGRR.

from videodb import SubtitleStyle

stream\_url = video.add\_subtitle(

SubtitleStyle(

primary\_colour ="&H00A5CFFF",

secondary\_colour ="&H00FFFF00",

outline\_colour ="&H000341C1",

back\_colour ="&H803B3B3B",

)

)

play\_stream(stream\_url)

![2.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-Ha_PSqmsVS/a6ebda91ff28cf30672254c305371b13fb09a4cb6d90506a80c2bd3a4b7f2a2a35e3145a00ef2e3e0094b6ca07b826a2e9639c59b62d1289d47011adc24e03c809b80ce2f2a6b18fdbeae134ca13fea6c03cb9b31fe9f82d24a8ef8e85e28446efb56cf9?auto=format%2Ccompress&fit=max)

### 3\. Position and Margins

Configure alignment and position of Subtitle by passing following parameters to SubtitleStyle() class

alignment : Alignment of subtitle. Accepts a value a type SubtitleAlignment

margin\_l : Sets margin area on left side of Subtitle box

margin\_r : Sets margin area on right side of Subtitle box

margin\_v : Sets margin area of top and bottom of Subtitle box

![info](https://cdn.coda.io/icons/svg/color/info.svg)

View API Reference to know more about SubtitleAlignment

from videodb import SubtitleStyle, SubtitleAlignment

stream\_url = video.add\_subtitle(

SubtitleStyle(

alignment =SubtitleAlignment.middle\_center,

margin\_l =10,

margin\_r =10,

margin\_v =20,

)

)

play\_stream(stream\_url)

![3.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-Ns4CGsQJtg/c7141f3d370e816e200096c04723829d596f81c180b943782d9c8c38645d444e9dc3a836ce866b6936bdbe9cca770eafd7decad46b52a3221d1f34b892139827ca84142b65712f74cb858c5af13dfb4554d8714936e4deb1ddb3f97f63caad16219fa3bb?auto=format%2Ccompress&fit=max)

### 4\. Text Transformation

Transform the text size and spacing by passing following parameters to SubtitleStyle() class

scale\_x : Factor for scaling of the font horizontally

scale\_y : Factor for scaling of the font vertically

angle : Rotation angle(degress) of the text

from videodb import SubtitleStyle

stream\_url = video.add\_subtitle(

SubtitleStyle(

scale\_x=1.5,

scale\_y=3,

angle=0,

)

)

play\_stream(stream\_url)

![4 (1).png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-2KhyB-qvsP/22c8db309f6cac65a380027a9ae88e2f368e8be2f5e7f8eb2dbdb8b9e5d6575ec0a667a86a35a8641302270288da8a5e151e8ae782d8f1535be6c8425b3ad83aaf52688120a46613d79d5c7a8b791d6d835b15662758635492b820daeffa939c55a02a15?auto=format%2Ccompress&fit=max)

### 5\. Borders and Shadow

Add border style, outline and shadow by passing following parameters to SubtitleStyle() class

border\_style : Border style of subtitle. Accepts a value a typeSubtitleBorderStyle

outline: The width(px) of the outline around the text.

shadow : The depth(px) of the shadow behind the text

![info](https://cdn.coda.io/icons/svg/color/info.svg)

View API Reference to know more about SubtitleBorderStyle

from videodb import SubtitleStyle, SubtitleBorderStyle

stream\_url = video.add\_subtitle(

style=SubtitleStyle(

shadow=2,

back\_colour="&H00000000",

border\_style=SubtitleBorderStyle.no\_border,

)

)

play\_stream(stream\_url)

![5.png](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-kWlndGvEzi/58b98f25313ddc0fc3f1b9fc1a2cafc0d9412970a541b320738008682a206b75e7d40ac3121ed202d04b274362c95cf36236837bd59e9027efc7ea04063567c9d63058cbdc4803bdd1a569694f4eb1c5f1a37f47c55bbe2564a0382e945e0f1966a83450?auto=format%2Ccompress&fit=max)

## üë®‚Äçüíª Next Steps

Check out the other resources and tutorials using Subtitle and Subtitle Styling üíÖ.

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

If you have any questions or feedback. Feel free to reach out to us üôåüèº

[Discord](https://discord.gg/py9P639jGz)

[GitHub](https://github.com/video-db)

[Email](mailto:ashu@videodb.io)

Adding Subtitles

üõ†Ô∏è Setup

üì¶ Installing packages

üîë API Keys

üåê Connect to VideoDB

üé• Upload Video

üîä Index Spoken Words

üìù Default Subtitles

üíÖ Custom Styled Subtitles

1\. Typography and Style

2\. Color and Effects

3\. Position and Margins

4\. Text Transformation

5\. Borders and Shadow

üë®‚Äçüíª Next Steps

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/e2903ec39b83/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (
CtrlP
) instead.


---

# Scene Extraction Algorithms [Source Link](https://docs.videodb.io/scene-extraction-algorithms-84)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)\\
\\
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)\\
\\
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)\\
\\
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)\\
\\
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)\\
\\
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)\\
\\
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)\\
\\
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)\\
\\
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![icon picker](https://cdn.coda.io/icons/svg/color/landscape.svg)\\
\\
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)\\
\\
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)\\
\\
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)\\
\\
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)\\
\\
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)\\
\\
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
\\
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)\\
\\
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)\\
\\
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)\\
\\
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)\\
\\
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)\\
\\
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)\\
\\
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)\\
\\
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)\\
\\
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)\\
\\
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)\\
\\
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)\\
\\
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)\\
\\
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)\\
\\
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)\\
\\
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)\\
\\
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)\\
\\
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)\\
\\
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)\\
\\
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)\\
\\
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)\\
\\
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)\\
\\
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)\\
\\
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)\\
\\
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)\\
\\
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)\\
\\
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)\\
\\
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)\\
\\
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)\\
\\
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)\\
\\
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)\\
\\
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)\\
\\
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)\\
\\
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)\\
\\
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)\\
\\
The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)\\
\\
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)\\
\\
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)\\
\\
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)\\
\\
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)\\
\\
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)\\
\\
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)\\
\\
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)\\
\\
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)\\
\\
Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)\\
\\
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)\\
\\
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)\\
\\
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)\\
\\
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)\\
\\
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)\\
\\
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)\\
\\
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)\\
\\
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)\\
\\
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)\\
\\
Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# ![icon picker](https://cdn.coda.io/icons/svg/color/landscape.svg) Scene Extraction Algorithms

## SceneExtractionType

A video is a series of images that are called frames, these frames can be processed using multimodal modals or computer vision pipelines. There are many ways to identify the temporal change of concepts in the video.

![Screenshot 2024-07-04 at 11.41.39 AM.jpg](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-HozdUmjeH4/7f7ec6d342e7b6ecb573aeeddb6e11b4d4529edb0b8188204fe1e2ca0545d2eda1b47369bbd32647998a8e1ec1cc326a800581717aa979ef19fb20850c76011cf4fb690f8a31cd48f44d7567597e85af1e57085261c25f70d5ef5cd5d74ae26f5c7909aa?auto=format%2Ccompress&fit=max)

SceneExtractionTypeand extraction\_configcan be used with two functions as parameters for scene identification.

It can be passed to index\_scenes() function as an argument.

It can be pass as an argument to extract\_scenes() function.

Checkout

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)\\
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

for Scene and Frame object details.

![Screenshot 2024-07-04 at 12.03.45 PM.jpg](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-YvzJ_wnCaf/689685ceab587445941fd8ded3ad89320d6995c066afd3f33f4f323db6bd1fceed4fd86d74fd1b4fd29b9d7cd58bb7919aeea0377e1341dab6fbf8e1c36ad1a074cf87c9606417597c8e810e29baa6fdaf52645800b8350c05176de46d97810914dcf77b?auto=format%2Ccompress&fit=max)

Time based extraction is a simple way to break video into scenes. You define a frequency at which you want to split the video in scenes, for example, you may consider every 10 second as a one scene. This method is useful when you have no information about the nature of video or the video is random & dynamic. You can even create scenes with 1 second time interval.

This method has following extraction\_config:

time : The interval (in seconds) at which scenes are segmented. Default value is 10 ‚Äî which means every 10 seconds segment is a scene.

frame\_count: The number of frames to extract per scene. This allows you to increase the number of frames collected for more context. Default value is 1.

select\_frames: A list of frames to select from each segment. The list can contain strings from \["first", "middle", or "last"\] which selects the respective frames. Default value is \["first"\]

Note: You can use either select\_frames or frame\_count strategy to extract frames for the scene.

wait\_index= traffic\_video.index\_scenes(

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time":4,"frame\_count":5},

prompt="Identify when multiple cars are slowing down or waiting. Mention that cars are waiting or stopping and also specify the lane as left, middle, or right. For example, you can say \`cars in the middle lanes are waiting\`.",

name="wait\_index"

)

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time":10,"select\_frames":\['first'\]},

![Screenshot 2024-07-04 at 12.13.39 PM.jpg](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-mwUiTJAjy5/8a6f84690e08bd9f79e83f541b72bc040dc6655ef5801cf27918d1c5e0acc2f5455f8a60b441ca513ea59d5e169bcd9a5bb219617b7b51bca6263d46e8b2cee70bd5ce8433351ca4bcabbc578af1d6aa91b54ec65bcca6ae5f523fbdc5c72fae926fa0fe?auto=format%2Ccompress&fit=max)

Videos share context between timestamps. A scene is a logical segment of a video that completes a concept. You can identify scene changes based on visual content within the video.

Key factors for calculating changes are significant changes in the visual content, such as transitions, lights and movement.

This method has following extraction\_config:

threshold: Determines the sensitivity of the model towards scene changes within the video. Default value is 20, which known to be good for detecting camera shot changes from a video.

frame\_count: Accepts a number that specifies how many frames to pick from each shot. Default value is 1. Increasing this number will result in more frames being selected from each shot, which could provide a more detailed analysis of the scene.

extraction\_type=SceneExtractionType.shot\_based,

extraction\_config={"threshold":20, "frame\_count":4},

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.

---

# Custom Annotations [Source Link](https://docs.videodb.io/custom-annotations-81)

VideoDB Documentation

Pages

*   [Welcome to VideoDB Docs](https://docs.videodb.io/)
*   [Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)
*   [How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)
*   [Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)
*   [Semantic Search](https://docs.videodb.io/semantic-search-89)
*   [Collections](https://docs.videodb.io/collections-68)
*   [Public Collections](https://docs.videodb.io/public-collections-102)
*   [Callback Details](https://docs.videodb.io/callback-details-66)
*   [Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)
*   [Language Support](https://docs.videodb.io/language-support-79)
*   [Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)
*   [Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)
*   [Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)
*   [Custom Annotations](https://docs.videodb.io/custom-annotations-81)
*   [Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)
*   [Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)
*   [Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)
*   [Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)
*   [Multimodal Search](https://docs.videodb.io/multimodal-search-90)
*   [Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)
*   [Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)
*   [Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)
*   [Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)
*   [Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)
*   [Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)
*   [Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)
*   [How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)
*   [Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)
*   [Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)
*   [Open Source Tools](https://docs.videodb.io/open-source-tools-94)
*   [LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)
*   [PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)
*   [StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)
*   [Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)
*   [Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)
*   [Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)
*   [Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)
*   [Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)
*   [Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)
*   [Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)
*   [Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)
*   [Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)
*   [Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)
*   [Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)
*   [Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)
*   [Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)
*   [Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)
*   [Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)
*   [AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)
*   [Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)
*   [AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)
*   [AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)
*   [Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)
*   [Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)
*   [Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)
*   [Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)
*   [Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)
*   [Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)
*   [Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)
*   [Society of Machines](https://docs.videodb.io/society-of-machines-20)
*   [Society of Machines](https://docs.videodb.io/society-of-machines-23)
*   [Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)
*   [Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)
*   [Drafts](https://docs.videodb.io/drafts-24)
*   [From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)
*   [The Future Series](https://docs.videodb.io/the-future-series-78)
*   [Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)
*   [Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)
*   [Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)
*   [Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)
*   [Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)
*   [What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)
*   [Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)
*   [Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)
*   [Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)
*   [Research Grants](https://docs.videodb.io/research-grants-96)
*   [Team](https://docs.videodb.io/team-46)
*   [Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)
*   [Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)
*   [Playlists](https://docs.videodb.io/playlists-33)
*   [Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)
*   [Ashish](https://docs.videodb.io/ashish-45)
*   [Shivani Desai](https://docs.videodb.io/shivani-desai-48)
*   [Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)
*   [Rohit Garg](https://docs.videodb.io/rohit-garg-64)
*   [Customer Love](https://docs.videodb.io/customer-love-42)
*   [Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# Custom Annotations

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/scene-index/custom_annotations.ipynb)

Enhance your understanding of videos by using our simple annotation and tagging pipeline. To enable this, you can create a new Scene object. Then, pass your annotations in the description field and index them using index\_scenes() function.

![Screenshot 2024-07-04 at 12.23.02 PM.jpg](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-sFF1gD6ccn/2b6d908fe9b544290d09b9d340cfa6ad521c2972dfe9756d8fe83c2d23a780a9838651fdfdf681a6eabb393922d6be3bd616d8af5e3b3edf3442b9f292d748a9660886c1bff1ece139e09954eec5c71a2748f019da510b9240d16fa88d5801faa410f129?auto=format%2Ccompress&fit=max)

VideoDB allows multiple indexes on video objects. This is advantageous as it allows you to attach additional context to each scene, enhancing the search functionality.

## Scene:

A Scene object describes a unique event in the video. From a timeline perspective it‚Äôs a timestamp range.

video\_id : id of the video object

start : seconds

end : seconds

description : string description

Each scene object has another attribute, frames, which contains a list of

[Frame](https://docs.videodb.io/advanced-visual-search-pipelines-82)

objects. However, we don't need them here for custom annotation pipelines because we are bringing the description from outside.

### Create a new Scene

Create new Scene objects and add your custom annotation as description.

```python
from videodb.scene import Scene

# create scene object and patch your description
scene1 = Scene(
    video_id=video.id,
    start=0,
    end=100,
    description="Detective Martin is being interviewed by the police.",)

scene2 = Scene(
    video_id=video.id,
    start=600,
    end=900,
    description="A religious gathering. People are praying and singing")

# create a list of scene objects
scenes = [scene1, scene2]
```

### Index and search scenes

Index using the list of scene objects and use the index\_id for search

```python
from videodb import IndexType

#create new index and assign it a name
index_id = video.index_scenes(scenes=scenes, name="My Custom Annotations#1")

# search using the index_id
res = video.search(query="religious gathering", index_type=IndexType.scene, index_id=index_id)

res.play()
```

Custom annotations unlock additional features

*   Adding application context into the search pipeline.
*   Generate unique descriptions from your own custom vision model.
*   Index manual annotations.

Read more about Scene object in

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

Scene:

*   Create a new Scene
*   Index and search scenes

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (CtrlP) instead.

---

# Scene-Level Metadata: Smarter Video Search & Retrieval [Source Link](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)

[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[Team](https://docs.videodb.io/team-46)

[Customer Love](https://docs.videodb.io/customer-love-42)

[Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# Scene-Level Metadata: Smarter Video Search & Retrieval

## Introduction

James and Mark are video engineers at leading sports entertainment companies, responsible for managing, storing, and editing vast amounts of sports footage. Their work requires them to extract and highlight the most exciting moments from hours of raw video.

Both rely on VideoDB to streamline their workflow, but their approaches differ.

Mark follows the traditional method: he indexes the entire video and runs a search for relevant scenes. VideoDB processes every indexed scene, analyzing descriptions either semantically or via keywords. The results are useful but not always efficient‚Äîespecially when the relevant content spans just a few minutes in a multi-hour video. The search still scans everything, sometimes returning unrelated clips.

James, on the other hand, has a smarter strategy. Instead of searching the entire video, he first filters out irrelevant scenes, ensuring that only important moments are considered. This results in faster and more precise searches. How does he achieve this? By using Scene-Level Metadata.

## What is Scene-Level Metadata?

Scene-Level Metadata acts as smart tags for individual video scenes, allowing them to be filtered during search. Instead of relying solely on text descriptions, VideoDB enables metadata-based filtering to refine search results and make retrieval more efficient.

### Why is this necessary?

Every video consists of multiple scenes, each composed of frames. By default, VideoDB scans every scene to find relevant content.

This works well for short videos, but when handling longer videos, only a few scenes may actually be relevant. Searching across the entire video can lead to:

Slower retrieval times

Less accurate results

By tagging scenes with metadata, we can focus the search only on relevant parts of the video, significantly improving accuracy and efficiency.

### How is Metadata Stored?

Metadata is stored as a dictionary in the Scene object, with a maximum of five key-value pairs per scene.

Here‚Äôs an example:

scene = Scene(

video\_id=video.id,

start=60,

end=62,

description="A Red Bull car speeds down the straight at Monza.",

metadata={"camera\_view":"road\_ahead","action\_type":"chasing"}

)

With Scene-Level Metadata, we can apply targeted filters, ensuring that searches return only highly relevant scenes.

## Example: Using Scene-Level Metadata in an F1 Race

James, our video engineer, works with Formula 1 race footage, which consists of continuous laps of high-speed action. To create engaging highlights, he needs to focus on the most thrilling moments:

Chasing battles

Sharp turns

Overtaking maneuvers

Dramatic crashes

Instead of searching the entire race, James applies Scene-Level Metadata to tag these key moments, ensuring faster and more accurate retrieval.

### Defining Metadata Filters

James decides to apply metadata filters using the "action\_type" key, assigning one of the following values:

üìå \["chase", "turn", "overtake", "crash"\]

For simplicity, he uses only one key-value pair per scene, but he could add multiple filters (e.g., "camera\_view", "lap\_number") for even more precise results.

## James' Workflow with VideoDB

### Step 1: Extract Scenes from the Footage

To improve indexing, James splits the video into 2-second scenes and extracts a single key frame per scene.

scene\_collection = video.extract\_scenes(

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time":2,"select\_frames":\["middle"\]}

)

scenes = scene\_collection.scenes # Fetch extracted scenes

### Step 2: Assign Metadata to Each Scene

James uses AI-powered descriptions to automatically tag scenes with the correct action type before indexing.

described\_scenes =\[\]

for scene in scenes:

# use describe to create smart metadata, category, filter etc.

action\_type = scene.describe('Select one: \["chase", "turn", "overtake", "crash"\]')

# use prompt to index contextual information that you need to search in vectors.

# use metadata to add structured information to each scene.

described\_scene = Scene(

video\_id=video.id,

start=scene.start,

end=scene.end,

description=scene.describe("Describe this scene briefly."),

metadata={"action\_type": action\_type}

)

described\_scenes.append(described\_scene)

### Step 3: Index the Video with Scene Metadata

Once metadata is assigned, James indexes the scenes for efficient searching.

scene\_index\_id = video.index\_scenes(

scenes=described\_scenes,

name="F1 Highlight Scenes"

)

### Step 4: Searching with Metadata Filters

Now, instead of searching the entire video, James can filter his search to focus on only specific race moments.

## Applying Metadata Filters in Search

### Example 1: Finding Intense Overtakes

To find all overtaking moments, James applies a metadata filter:

search\_results = video.search(

query="A thrilling overtaking maneuver",

filter=\[{"action\_type":"overtake"}\],# Apply metadata filter

search\_type=SearchType.semantic,

index\_type=IndexType.scene,

scene\_index\_id=scene\_index\_id

)

search\_results.play()# View the retrieved scenes

### Example 2: Finding Chase Scenes in the Race

To retrieve close pursuit moments, James filters for chase scenes:

search\_results = video.search(

query="An aggressive chase on the track",

filter=\[{"action\_type":"chase"}\],# Apply metadata filter

search\_type=SearchType.semantic,

index\_type=IndexType.scene,

scene\_index\_id=scene\_index\_id

)

search\_results.play()

By applying Scene-Level Metadata, James dramatically improves his video search workflow.

## Index level Metadata

metadata can be passed as parameter to the index\_scenes function as well.

scene\_index\_id= video.index\_scenes(

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time":540},

metadata={"category":"news","topic":"airplane"},

)

The metadata you passed during the indexing process, would apply to all the scenes that you are indexing.

Depending on your application, you may have additional scene-related metadata, which can be included within the metadata parameter. Please refer to the metadata guidelines.

Metadata Guidelines:

metadata must be a dictionary containing key-value pairs.

Both keys and values can be of type int or string.

A maximum of 5 key-value pairs is allowed.

The length of keys and values must not exceed 20 characters.

Filter results based on your criteria and you can pass more than one filter. This can be useful in timestamp based filtering of results, while exploring archival content and many such more categorical approaches to find the right content.

results= video.search(

query="airport",

filter=\[{"category":"news"}\],

index\_type=IndexType.scene

)

results= coll.search(

query="airport",

filter=\[{"category":"news"}\],

index\_type=IndexType.scene

)

Filter Guidelines:

Filter must be a list of dictionaries.

Each dictionary specifies a key-value pair to filter the results based on metadata.

## Expanding the Use Cases

Metadata isn't just for sports highlights‚Äîit has applications across multiple industries:

üîπ Wildlife Documentation
A raw wildlife documentary may contain hours of footage capturing slow-moving landscapes and sudden bursts of animal activity. But let‚Äôs say we‚Äôre only interested in tracking a pride of lions. With metadata tagging, we can filter out only the scenes featuring lions, making it easier to find the right content.

üîπ Tech Conferences & Keynote Events
A multi-hour tech conference covers various topics‚ÄîBlockchain, GenAI, Quantum Computing, etc. Instead of searching through entire sessions, we can tag segments based on their subjects and filter out irrelevant sections, making topic-based retrieval seamless.

üîπ Security & Surveillance
In CCTV surveillance, hours of footage may contain only a few moments of interest, such as unauthorized access or suspicious activity. By tagging scenes based on motion detection, time of day, or facial recognition, security teams can instantly retrieve critical footage.

## The Future of Smart Video Retrieval

Scene-Level Metadata is a game-changer in video indexing and retrieval. It enhances:

‚úÖ Precision ‚Äì Finds exactly what you‚Äôre looking for.
‚úÖ Efficiency ‚Äì Speeds up the search process.
‚úÖ Scalability ‚Äì Works with large video datasets effortlessly.

From Formula 1 highlights to security footage analysis, metadata-driven search makes video retrieval faster, smarter, and more intuitive than ever before.

With VideoDB, every second of footage becomes instantly accessible.

Introduction

What is Scene-Level Metadata?

Why is this necessary?

How is Metadata Stored?

Example: Using Scene-Level Metadata in an F1 Race

Defining Metadata Filters

James' Workflow with VideoDB

Step 1: Extract Scenes from the Footage

Step 2: Assign Metadata to Each Scene

Step 3: Index the Video with Scene Metadata

Step 4: Searching with Metadata Filters

Applying Metadata Filters in Search

Example 1: Finding Intense Overtakes

Example 2: Finding Chase Scenes in the Race

Index level Metadata

Expanding the Use Cases

The Future of Smart Video Retrieval

Want to print your doc?

This is not the way.

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Advanced Visual Search Pipelines [Source Link](https://docs.videodb.io/advanced-visual-search-pipelines-82)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg)
Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg)
Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg)
How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)
Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg)
Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg)
Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg)
Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg)
Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg)
Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg)
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg)
Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg)
Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)
Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![](https://cdn.coda.io/icons/svg/color/football.svg)
Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg)
Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg)
Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg)
Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg)
Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)
Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg)
Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg)
Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg)
How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg)
Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg)
Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg)
PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg)
StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg)
Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg)
Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg)
Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)
Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)
Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg)
Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg)
Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg)
Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg)
Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg)
Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg)
Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg)
Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg)
Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg)
Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)
Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg)
AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg)
Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg)
AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg)
AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg)
Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg)
Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg)
Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg)
Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg)
Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)
Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg)
Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg)
Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg)
Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg)
Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg)
From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg)
The Future Series](https://docs.videodb.io/the-future-series-78)

[![](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg)
Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg)
Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg)
Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg)
Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg)
What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg)
Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg)
Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg)
Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg)
Team](https://docs.videodb.io/team-46)

[![](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)
Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg)
Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg)
Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg)
Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg)
Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg)
Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg)
Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg)
Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg)
Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg)
Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# ![icon picker](https://cdn.coda.io/icons/svg/color/search-more.svg) Advanced Visual Search Pipelines

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/scene-index/advanced_visual_search.ipynb)

Let's deep dive into Scene and Frame objects

### Scene

A Scene object describes a unique event in the video. From a timeline perspective it‚Äôs a timestamp range.

![info](https://cdn.coda.io/icons/svg/color/info.svg)

video\_id : id of the video object

start : seconds

end : seconds

description : string description

Each scene object has an attribute frames, that has list of Frame objects.

### Frame

Each Scene can be described by a list of frames. Each Frame object primarily has the URL of the image and its description field.

![info](https://cdn.coda.io/icons/svg/color/info.svg)

id : ID of the frame object

url : URL of the image

frame\_time : Timestamp of the frame in the video

description : string description

video\_id : id of the video object

scene\_id : id of the scene object

![Screenshot 2024-07-04 at 11.41.39 AM.jpg](https://codaio.imgix.net/docs/_s5lUnUCIU/blobs/bl-HozdUmjeH4/7f7ec6d342e7b6ecb573aeeddb6e11b4d4529edb0b8188204fe1e2ca0545d2eda1b47369bbd32647998a8e1ec1cc326a800581717aa979ef19fb20850c76011cf4fb690f8a31cd48f44d7567597e85af1e57085261c25f70d5ef5cd5d74ae26f5c7909aa?auto=format%2Ccompress&fit=max)

We provide you with easy-to-use Objects and Functions to bring flexibility in designing your visual understanding pipeline. With these tools, you have the freedom to:

Extract scene according to your use case.

Go to frame level abstraction.

Assign label, custom model description for each frame.

Use of multiple models, prompts for each scene or frame to convert information to text.

Send multiple frames to vision model for better temporal activity understanding.

### extract\_scenes()

This function accepts the extraction\_type and extraction\_config and returns a
[SceneCollection](https://docs.videodb.io/playground-for-scene-extractions-83)

object, which keep information about all the extracted scene lists.

Checkout
[![](https://cdn.coda.io/icons/svg/color/landscape.svg)
Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

for more details.

scene\_collection = video.extract\_scenes(

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time": 30, "select\_frames": \["middle"\]},

)

### Capture Temporal Change

Vision models excel at describing images, but videos present an added complexity due to the temporal changes in the information. With our pipeline, you can maintain image-level understanding in frames and combine them using LLMs at the scene level to capture temporal or activity-related understanding.

You have freedom to iterate through each scene and frame level to describe the information for indexing purposes.

Get scene collection

scene\_collection = video.get\_scene\_collection("scene\_collection\_id")

### Iterate through each scene and frame

Iterate over scenes and frames and attach description coming from external pipeline be it custom CV pipeline or custom model descriptions.

print("This is scene collection id", scene\_collection.id)

print("This is scene collection config", scene\_collection.config)

\# get scene from collection

scenes = scene\_collection.scenes

\# Iterate through each scene

for scene in scenes:

print(f"Scene Duration {scene.start}-{scene.end}")

# Iterate through each frame in the scene

for frame in scene.frames:

print(f"Frame at {frame.frame\_time} {frame.url}")

frame.description = "bring text from external sources/ pipeline"

)

### Create Scene by custom annotation

These annotations can come from your application or from external vision model, if you extract the description using any vision LLM

for scene in scenes:

scene.description = "summary of frame level description"

Using this pipeline, you have the freedom to design your own flow. In the example above, we‚Äôve described each frame in the scene independently, but some vision models allow multiple images in one go as well. Feel free to customise your flow as per your needs.

Experiment with sending multiple frames to a vision model.

Utilize prompts to describe multiple frames, then assign these descriptions to the scene.

Integrate your own vision model into the pipeline.

![light](https://cdn.coda.io/icons/svg/color/light.svg)

We‚Äôll soon be adding more details and strategies for effective and advanced multimodal search. We welcome your input on what strategies have worked best in your specific use cases

Here‚Äôs our üéôÔ∏è

[Discord](https://discord.gg/py9P639jGz)

channel where we brainstorm about such ideas.

Once you have a description of each scene in place, you can index and search for the information using the following functions.

from videodb import IndexType

#create new index and assign a name to it

index\_id = video.index\_scenes(scenes=scenes, name="My Custom Model")

\# search using the index\_id

res = video.search(query="first 29 sec",

index\_type=IndexType.scene,

index\_id=index\_id)

res.play()

Scene

Frame

extract\_scenes()

Capture Temporal Change

Iterate through each scene and frame

Create Scene by custom annotation

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.

---

# Playground for Scene Extractions [Source Link](https://docs.videodb.io/playground-for-scene-extractions-83)

![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF)

VideoDB Documentation

Pages

[![](https://cdn.coda.io/icons/svg/color/align-center.svg) Welcome to VideoDB Docs](https://docs.videodb.io/)

[![](https://cdn.coda.io/icons/svg/color/quick-mode-on.svg) Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[![](https://cdn.coda.io/icons/svg/color/wash-your-hands.svg) How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg) Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg) Semantic Search](https://docs.videodb.io/semantic-search-89)

[![](https://cdn.coda.io/icons/svg/color/binders-folder.svg) Collections](https://docs.videodb.io/collections-68)

[![](https://cdn.coda.io/icons/svg/color/magazine.svg) Public Collections](https://docs.videodb.io/public-collections-102)

[![](https://cdn.coda.io/icons/svg/color/callback.svg) Callback Details](https://docs.videodb.io/callback-details-66)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg) Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[![](https://cdn.coda.io/icons/svg/color/customer-support.svg) Language Support](https://docs.videodb.io/language-support-79)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg) Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[![](https://cdn.coda.io/icons/svg/color/asteroid.svg) Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[![](https://cdn.coda.io/icons/svg/color/landscape.svg) Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[![](https://cdn.coda.io/icons/svg/color/edit-column.svg) Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[![](https://cdn.coda.io/icons/svg/color/search-property.svg) Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg) Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[![icon picker](https://cdn.coda.io/icons/svg/color/football.svg) Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[![](https://cdn.coda.io/icons/svg/color/scuba-pressure-gauge.svg) Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[![](https://cdn.coda.io/icons/svg/color/clear-search.svg) Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[![](https://cdn.coda.io/icons/svg/color/search-more.svg) Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[![](https://cdn.coda.io/icons/svg/color/poll-topic.svg) Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[![](https://cdn.coda.io/icons/svg/color/e-learning.svg) Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg) Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[![](https://cdn.coda.io/icons/svg/color/text-box.svg) Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[![director-light](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/6bc288c2-982b-4a97-a402-8da53aeaa236?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF) Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[![](https://cdn.coda.io/icons/svg/color/open-book.svg) Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[![](https://cdn.coda.io/icons/svg/color/bag-front-view.svg) How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[![](https://cdn.coda.io/icons/svg/color/voice-recognition-scan.svg) Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[![](https://cdn.coda.io/icons/svg/color/console.svg) Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[![github](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/ac14f3ef-daa1-4b6e-aba5-af11f11b8372?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF) Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[![llama](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/c2b3a994-6140-40a9-93ff-d87aa37f2860?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF) LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[![](https://cdn.coda.io/icons/svg/color/command-line.svg) PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[![](https://cdn.coda.io/icons/svg/color/day-camera.svg) StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[![](https://cdn.coda.io/icons/svg/color/book-and-pencil.svg) Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[![](https://cdn.coda.io/icons/svg/color/audible.svg) Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[![](https://cdn.coda.io/icons/svg/color/adware-free.svg) Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg) Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg) Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[![](https://cdn.coda.io/icons/svg/color/insert-white-space.svg) Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[![](https://cdn.coda.io/icons/svg/color/mac-client.svg) Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[![](https://cdn.coda.io/icons/svg/color/adverb.svg) Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[![](https://cdn.coda.io/icons/svg/color/medium-volume.svg) Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[![](https://cdn.coda.io/icons/svg/color/camera-automation.svg) Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[![](https://cdn.coda.io/icons/svg/color/video-trimming.svg) Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[![](https://cdn.coda.io/icons/svg/color/closed-captioning.svg) Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[![](https://cdn.coda.io/icons/svg/color/high-volume.svg) Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[![](https://cdn.coda.io/icons/svg/color/video-call.svg) Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg) Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[![](https://cdn.coda.io/icons/svg/color/billboard.svg) AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[![](https://cdn.coda.io/icons/svg/color/search.svg) Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[![](https://cdn.coda.io/icons/svg/color/find-and-replace.svg) AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[![](https://cdn.coda.io/icons/svg/color/find-user-male.svg) AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[![](https://cdn.coda.io/icons/svg/color/counter.svg) Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[![](https://cdn.coda.io/icons/svg/color/handle-with-care.svg) Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[![](https://cdn.coda.io/icons/svg/color/centre-of-gravity.svg) Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[![](https://cdn.coda.io/icons/svg/color/for-experienced.svg) Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg) Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[![](https://cdn.coda.io/icons/svg/color/panel-and-foot-outlet.svg) Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg) Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[![](https://cdn.coda.io/icons/svg/color/cnc-machine.svg) Society of Machines](https://docs.videodb.io/society-of-machines-20)

[![](https://cdn.coda.io/icons/svg/color/groups.svg) Society of Machines](https://docs.videodb.io/society-of-machines-23)

[![](https://cdn.coda.io/icons/svg/color/the-flash-sign.svg) Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg) Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[![](https://cdn.coda.io/icons/svg/color/back-to-draft.svg) Drafts](https://docs.videodb.io/drafts-24)

[![](https://cdn.coda.io/icons/svg/color/one-to-many.svg) From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[![](https://cdn.coda.io/icons/svg/color/recurring-appointment-exception.svg) The Future Series](https://docs.videodb.io/the-future-series-78)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF) Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[![](https://cdn.coda.io/icons/svg/color/video.svg) Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[![](https://cdn.coda.io/icons/svg/color/synchronize.svg) Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[![](https://cdn.coda.io/icons/svg/color/bridge.svg) Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[![](https://cdn.coda.io/icons/svg/color/need-for-speed.svg) Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[![](https://cdn.coda.io/icons/svg/color/questions.svg) What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[![](https://cdn.coda.io/icons/svg/color/ai.svg) Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg) Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[![](https://cdn.coda.io/icons/svg/color/fff.svg) Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[![](https://cdn.coda.io/icons/svg/color/biotech.svg) Research Grants](https://docs.videodb.io/research-grants-96)

[![](https://cdn.coda.io/icons/svg/color/the-dragon-team.svg) Team](https://docs.videodb.io/team-46)

[![videodb](https://codaio.imgix.net/workspaces/ws-jizMKG73gK/blobs/customIcons/1a6d553a-3676-494e-8f3b-fd666614f459?fit=fill&fill=solid&w=128&h=128&fm=gif&bg=0FFF&fill-color=0FFF) Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[![](https://cdn.coda.io/icons/svg/color/light.svg) Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[![](https://cdn.coda.io/icons/svg/color/fast-forward.svg) Playlists](https://docs.videodb.io/playlists-33)

[![](https://cdn.coda.io/icons/svg/color/1.svg) Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[![](https://cdn.coda.io/icons/svg/color/rocket.svg) Ashish](https://docs.videodb.io/ashish-45)

[![](https://cdn.coda.io/icons/svg/color/edvard-munch.svg) Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[![](https://cdn.coda.io/icons/svg/color/artificial-intelligence.svg) Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[![](https://cdn.coda.io/icons/svg/color/under-computer.svg) Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[![](https://cdn.coda.io/icons/svg/color/like.svg) Customer Love](https://docs.videodb.io/customer-love-42)

[![](https://cdn.coda.io/icons/svg/color/llama.svg) Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# ![icon picker](https://cdn.coda.io/icons/svg/color/football.svg) Playground for Scene Extractions

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/scene-index/playground_scene_extraction.ipynb)

## Playground: Extract Scenes without Indexing

Sometimes, it's important to determine the number of scenes needed to describe a video, as this can vary depending on the type of video. For instance, videos of a podcast with two hosts tend to be less dynamic than sports videos

![light](https://cdn.coda.io/icons/svg/color/light.svg)

If you want to extract scenes from the video without indexing them, you can use the video.extract\_scenes()function.

Using this pipeline you can experiment with scene extraction and find your suitable configuration.

### extract\_scenes()

This function accepts the extraction\_type and extraction\_config and returns a SceneCollection object, that keeps the information about all the extracted scene lists.

scene\_collections = video.extract\_scenes(

extraction\_type=SceneExtractionType.time\_based,

extraction\_config={"time": 30, "select\_frames": \["middle"\]},

)

### SceneCollection Viewing, Inspecting, and Deleting Scenes

For every scene extraction pipeline that you run on a video, a SceneCollection object is created.

You can use following functions to View, Inspect and Delete your SceneCollections

list\_scene\_collection

scene\_collections = video.list\_scene\_collection()

for scene\_collection in scene\_collections:

print("Scene Collection ID :",scene\_collection\["scene\_collection\_id"\])

Get SceneCollection by ID

scene\_collection = video.get\_scene\_collection("scene\_collection\_id")

Inspecting SceneCollection

print("This is scene collection id", scene\_collection.id)

print("This is scene collection config", scene\_collection.config)

## Playground: Play with Prompt

Before finalizing your prompt, consider experimenting with different ones. This will help you see how the search performs for your use cases. Start by iterating over only a few scenes. Then, experiment with your prompt and test it after indexing

We believe that the right prompt is very helpful in finding information that aligns with your domain knowledge and experience. For this we provide following describe(prompt= ) functions at Frame and Scene level.

[Read more about Scene and Frame object](https://docs.videodb.io/advanced-visual-search-pipelines-82)

#describe frame image using vision LLM

frame.describe(

prompt=str,

)

\# run vision model on scene level

\# primarily for activity detection.

Scene.describe(

prompt=str,

)

Start by iterating over only few scenes and experiment with your prompt and test after indexing.

\# get scene from collection

scenes = scene\_collection.scenes

\# Iterate through only 5 scene

for scene in scenes\[:5\]:

print(f"Scene Duration {scene.start}-{scene.end}")

# Iterate through each frame in the scene

for frame in scene.frames:

print(f"Frame at {frame.frame\_time} {frame.url}")

frame.describe(

prompt=str,

)

### Experiment with prompt at scene level

\# get scene from collection

scenes = scene\_collection.scenes

\# Iterate through first 5 scene

for scene in scenes\[:5\] :

scene.describe(

prompt=str,

)

### Index and search scenes

\# Give a name to your index for reference

index\_id = video.index\_scenes(scenes=scenes, name="")

\# search using the index\_id

res = video.search(query="religious gathering",

index\_type=IndexType.scene,

index\_id=index\_id)

res.play()

Playground: Extract Scenes without Indexing

extract\_scenes()

SceneCollection Viewing, Inspecting, and Deleting Scenes

Playground: Play with Prompt

Experiment with prompt at scene level

Index and search scenes

Want to print your doc?

This is not the way.

![](https://cdn.coda.io/assets/6ee7d0564a67/img/import_google_docs.png)

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (

CtrlP

) instead.


---

# Deep Dive into Prompt Engineering : Mastering Video Scene Indexing [Source Link](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

VideoDB Documentation

Pages

[Welcome to VideoDB Docs](https://docs.videodb.io/)

[Quick Start Guide](https://docs.videodb.io/quick-start-guide-38)

[How Accurate is Your Search?](https://docs.videodb.io/how-accurate-is-your-search-88)

[Video Indexing Guide](https://docs.videodb.io/video-indexing-guide-101)

[Semantic Search](https://docs.videodb.io/semantic-search-89)

[Collections](https://docs.videodb.io/collections-68)

[Public Collections](https://docs.videodb.io/public-collections-102)

[Callback Details](https://docs.videodb.io/callback-details-66)

[Ref: Subtitle Styles](https://docs.videodb.io/ref-subtitle-styles-57)

[Language Support](https://docs.videodb.io/language-support-79)

[Guide: Subtitles](https://docs.videodb.io/guide-subtitles-73)

[Visual Search and Indexing](https://docs.videodb.io/visual-search-and-indexing-80)

[Scene Extraction Algorithms](https://docs.videodb.io/scene-extraction-algorithms-84)

[Custom Annotations](https://docs.videodb.io/custom-annotations-81)

[Scene-Level Metadata: Smarter Video Search & Retrieval](https://docs.videodb.io/scene-level-metadata-smarter-video-search-retrieval-107)

[Advanced Visual Search Pipelines](https://docs.videodb.io/advanced-visual-search-pipelines-82)

[Playground for Scene Extractions](https://docs.videodb.io/playground-for-scene-extractions-83)

[Deep Dive into Prompt Engineering : Mastering Video Scene Indexing](https://docs.videodb.io/deep-dive-into-prompt-engineering-mastering-video-scene-indexing-93)

[Multimodal Search](https://docs.videodb.io/multimodal-search-90)

[Multimodal Search: Quickstart](https://docs.videodb.io/multimodal-search-quickstart-91)

[Conference Slide Scraper with VideoDB](https://docs.videodb.io/conference-slide-scraper-with-videodb-92)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-44)

[Ref: TextAsset](https://docs.videodb.io/ref-textasset-74)

[Guide : TextAsset](https://docs.videodb.io/guide-textasset-75)

[Director - Video Agent Framework](https://docs.videodb.io/director-video-agent-framework-98)

[Agent Creation Playbook](https://docs.videodb.io/agent-creation-playbook-103)

[How I Built a CRM-integrated Sales Assistant Agent in 1 Hour](https://docs.videodb.io/how-i-built-a-crm-integrated-sales-assistant-agent-in-1-hour-106)

[Make Your Video Sound Studio Quality with Voice Cloning](https://docs.videodb.io/make-your-video-sound-studio-quality-with-voice-cloning-105)

[Setup Director Locally](https://docs.videodb.io/setup-director-locally-104)

[Open Source Tools](https://docs.videodb.io/open-source-tools-94)

[LlamaIndex VideoDB Retriever](https://docs.videodb.io/llamaindex-videodb-retriever-58)

[PromptClip: Use Power of LLM to Create Clips](https://docs.videodb.io/promptclip-use-power-of-llm-to-create-clips-52)

[StreamRAG: Connect ChatGPT to VideoDB](https://docs.videodb.io/streamrag-connect-chatgpt-to-videodb-43)

[Examples and Tutorials](https://docs.videodb.io/examples-and-tutorials-35)

[Dubbing - Replace Soundtrack with New Audio](https://docs.videodb.io/dubbing-replace-soundtrack-with-new-audio-49)

[Beep curse words in real-time](https://docs.videodb.io/beep-curse-words-in-real-time-53)

[Remove Unwanted Content from videos](https://docs.videodb.io/remove-unwanted-content-from-videos-5)

[Instant Clips of Your Favorite Characters](https://docs.videodb.io/instant-clips-of-your-favorite-characters-3)

[Insert Dynamic Ads in real-time](https://docs.videodb.io/insert-dynamic-ads-in-real-time-7)

[Adding Brand Elements with VideoDB](https://docs.videodb.io/adding-brand-elements-with-videodb-76)

[Revolutionize Video Editing with VideoDb: Effortless Ad Placement and Seamless Video Integration](https://docs.videodb.io/revolutionize-video-editing-with-videodb-effortless-ad-placement-8)

[Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage](https://docs.videodb.io/eleven-labs-x-videodb-adding-ai-generated-voiceovers-to-silent-f-59)

[Elevating Trailers with Automated Narration](https://docs.videodb.io/elevating-trailers-with-automated-narration-60)

[Add Intro/Outro to Videos](https://docs.videodb.io/add-intro-outro-to-videos-61)

[Enhancing Video Captions with VideoDB Subtitle Styling](https://docs.videodb.io/enhancing-video-captions-with-videodb-subtitle-styling-62)

[Audio overlay + Video + Timeline](https://docs.videodb.io/audio-overlay-video-timeline-63)

[Building Dynamic Video Streams with VideoDB: Integrating Custom Data and APIs](https://docs.videodb.io/building-dynamic-video-streams-with-videodb-integrating-custom-d-85)

[Adding AI Generated Voiceovers with VideoDB and LOVO](https://docs.videodb.io/adding-ai-generated-voiceovers-with-videodb-and-lovo-70)

[AI Generated Ad Films for Product Videography: Wellsaid, Open AI & VideoDB](https://docs.videodb.io/ai-generated-ad-films-for-product-videography-wellsaid-open-ai-v-71)

[Fun with Keyword Search](https://docs.videodb.io/fun-with-keyword-search-77)

[AWS Rekognition and VideoDB - Intelligent Video Clips](https://docs.videodb.io/aws-rekognition-and-videodb-intelligent-video-clips-4)

[AWS Rekognition and VideoDB - Effortlessly Remove Inappropriate Content from Video](https://docs.videodb.io/aws-rekognition-and-videodb-effortlessly-remove-inappropriate-co-6)

[Overlay a Word-Counter on Video Stream](https://docs.videodb.io/overlay-a-word-counter-on-video-stream-86)

[Generate Automated Video Outputs with Text Prompts \| DALL-E + ElevenLabs + OpenAI + VideoDB](https://docs.videodb.io/generate-automated-video-outputs-with-text-prompts-dall-e-eleven-87)

[Edge of Knowledge](https://docs.videodb.io/edge-of-knowledge-10)

[Building Intelligent Machines](https://docs.videodb.io/building-intelligent-machines-16)

[Part 1 - Define Intelligence](https://docs.videodb.io/part-1-define-intelligence-17)

[Part 2 - Observe and Respond](https://docs.videodb.io/part-2-observe-and-respond-18)

[Part 3 - Training a Model](https://docs.videodb.io/part-3-training-a-model-19)

[Society of Machines](https://docs.videodb.io/society-of-machines-20)

[Society of Machines](https://docs.videodb.io/society-of-machines-23)

[Autonomy - Do we have the choice?](https://docs.videodb.io/autonomy-do-we-have-the-choice-21)

[Emergence - An Intelligence of the collective](https://docs.videodb.io/emergence-an-intelligence-of-the-collective-22)

[Drafts](https://docs.videodb.io/drafts-24)

[From Language Models to World Models: The Next Frontier in AI](https://docs.videodb.io/from-language-models-to-world-models-the-next-frontier-in-ai-65)

[The Future Series](https://docs.videodb.io/the-future-series-78)

[Building World's First Video Database](https://docs.videodb.io/building-worlds-first-video-database-25)

[Multimedia: From MP3/MP4 to the Future with VideoDB](https://docs.videodb.io/multimedia-from-mp3-mp4-to-the-future-with-videodb-26)

[Introducing VideoDB: The Pinnacle of Synchronized Video Streaming for the Modern Web](https://docs.videodb.io/introducing-videodb-the-pinnacle-of-synchronized-video-streaming-27)

[Dynamic Video Streams](https://docs.videodb.io/dynamic-video-streams-50)

[Why do we need a Video Database Now?](https://docs.videodb.io/why-do-we-need-a-video-database-now-41)

[What's a Video Database ?](https://docs.videodb.io/whats-a-video-database-36)

[Enhancing AI-Driven Multimedia Applications](https://docs.videodb.io/enhancing-ai-driven-multimedia-applications-37)

[Misalignment of Today's Web](https://docs.videodb.io/misalignment-of-todays-web-67)

[Beyond Traditional Video Infrastructure](https://docs.videodb.io/beyond-traditional-video-infrastructure-28)

[Research Grants](https://docs.videodb.io/research-grants-96)

[Team](https://docs.videodb.io/team-46)

[Internship: Build the Future of AI-Powered Video Infrastructure](https://docs.videodb.io/internship-build-the-future-of-ai-powered-video-infrastructure-97)

[Ashutosh Trivedi](https://docs.videodb.io/ashutosh-trivedi-32)

[Playlists](https://docs.videodb.io/playlists-33)

[Talks - Solving Logical Puzzles with Natural Language Processing - PyCon India 2015](https://docs.videodb.io/talks-solving-logical-puzzles-with-natural-language-processing-p-34)

[Ashish](https://docs.videodb.io/ashish-45)

[Shivani Desai](https://docs.videodb.io/shivani-desai-48)

[Gaurav Tyagi](https://docs.videodb.io/gaurav-tyagi-51)

[Rohit Garg](https://docs.videodb.io/rohit-garg-64)

[Customer Love](https://docs.videodb.io/customer-love-42)

[Temp Doc](https://docs.videodb.io/temp-doc-54)

Visual Search and Indexing

# Deep Dive into Prompt Engineering : Mastering Video Scene Indexing

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/multimodal/Prompt_Experiments_and_Benchmarking.ipynb)

## Introduction:

As developers working on video processing, we often face challenges in accurately indexing and describing complex scenes. This blog post explores how strategic prompt engineering can significantly enhance our ability to extract detailed information from video frames, opening up new possibilities for advanced video search and analysis.

## Goal of the Experiment:

Our primary objective was to demonstrate how refined prompts can significantly improve search results and information extraction from video content. We aimed to create a system capable of accurately identifying objects, actions, and even emotions in various video scenes. For this particular experiment, we used video footage from a
[dog show](https://youtu.be/_T3n-2zOrZQ?si=lY9JnkKPQq1WhwMk)
, featuring various breeds walking down a runway with their handlers, surrounded by spectators and photographers. Our goal was to create prompts that could answer detailed queries like "Show me the happiest moments featuring a Golden Retriever" with high precision.

## Frame-Level vs Scene-Level Prompting:

In our experiment, we explored both frame-level and scene-level prompting:

Frame-level prompts focus on extracting information from individual frames.

Scene-level prompts analyze a series of frames to describe the overall action.

Important Considerations:

Computational Cost: Frame-level descriptions, while providing granular detail, are computationally heavy and potentially costly. It's not always necessary or efficient to use them for every use case.

Strategic Approach: A recommended strategy is to use frame prompts as a tuning mechanism. By testing and refining frame-level prompts, we can identify the most effective way to extract information from the vision model. Once optimized, we can incorporate these insights into scene-level prompts, potentially achieving high accuracy without the computational overhead of frame-by-frame analysis.

Let's walk through our prompt iterations and their outputs:

## Frame-level Prompts:

### ‚úçÔ∏è Frame Prompt 1: Basic animal identification

frame\_prompt ="""

You will be provided with an image. Your task is to identify and describe the animals in the image.

1. Identify Animals: List distinct animals in the image.

2. Describe animals: Provide a brief description of each animal, including breed, color, and any other notable features.

"""

Output:

[
{
"name":"dog",
"context":"a grey dog is being led down the green carpet by a person wearing a blue jacket."
}
]

This output lacked specificity in breed identification and environmental context. Our next prompt aims to address these issues.

### ‚úçÔ∏è Frame Prompt 2: Enhanced breed identification and spatial information

frame\_prompt ="""

You will be provided with an image. Your task is to identify the animals and their breeds in the image.

1. Identify Animals: List distinct animals and their breed in the image.

2. Describe the environment: Provide a brief description of the interaction between the animals and the objects or the environment around them.

"""

Output:

[
{
"name":"Dog - Poodle",
"context":"A Poodle being led down a carpeted path by a handler in the green dress, participating in what appears to be a dog show."
},
{
"name":"Dog - Russell Terrier",
"context":"A Russell Terrier being guided by a handler in black attire on the same path, also taking part in the dog show."
}
]

This output significantly improved breed identification and provided more environmental context. With this satisfactory frame-level output, we're now ready to incorporate these learnings into scene-level prompts.

However, let's first examine what a generic scene-level prompt can achieve without the added context from our frame-level experiments.

## Scene-level

### ‚úèÔ∏è Scene Prompt 1: Basic scene-level prompt

scene\_prompt ="""

You will be provided with a series of images. Your task is to view all images together and describe the overall story or scene in the best possible way.

Expected Output:

- A detailed story or scene description.

- A list of objects and actions in each image.

Example Output:

{
"scene\_story": "A person is cooking in the kitchen and then someone rings the doorbell.",
"images": [
{"description": "Someone is cooking in the kitchen."},
{"description": "Someone rings the doorbell."}
]
}

"""

Output:

{
"scene\_story":"A dog show competition where handlers are presenting their dogs on a green runway surrounded by an audience and judges.",
"images":[
{"description":"Handlers walking dogs down a green carpeted runway."},
{"description":"Spectators and photographers observing the dog show."},
{"description":"Judges evaluating the dogs as they pass by."}
]
}

Note: This generic scene-level prompt provided a basic structure but lacked the detailed breed identification and specific actions we achieved with our frame-level prompts. Our next iteration aims to incorporate these learnings.

### ‚úèÔ∏è Scene Prompt 2: Combining frame-level specifications in scene-level prompt

scene\_prompt ="""

You will be provided with a series of images. Your task is to view all images together and describe the overall story or scene in the best possible way.

For each image, your task is to identify the animals and their breeds in the image.

1. Identify the animals present in the frame with specifications about their colour and breed, and any other notable features.

2. Describe the environment: Provide a brief description of the interaction between the animals and the objects or the environment around them.

"""

Output:

{
"scene\_story":"A dog show is ongoing where handlers are showcasing their dogs on a designated runway, surrounded by spectators and event staff.",
"images":[
{
"description":"Three handlers are walking their dogs on a green carpeted runway. The runway is fenced and lined with purple banners. There are numerous spectators and photographers capturing the event. One dog is a white and brown breed, possibly a Jack Russell Terrier, and the other is a medium-sized, grey wavy-haired breed, potentially a Poodle."
},
{
"description":"The scene is similar with the dogs and handlers moving further along the runway. The same dogs, a Jack Russell Terrier and a grey Poodle, are being showcased. The audience continues to watch and photograph the event."
},
{
"description":"The handlers and dogs are closer to the end of the runway. The dogs remain the primary focus, with one being a Jack Russell Terrier and the other a grey Poodle. The spectators and photographers are actively engaged in observing the dogs."
}
]
}

Note: This output successfully incorporated breed identification and more detailed actions, but still lacked some specificity in describing multiple animals in a single frame. Our next iteration addresses this.

### ‚úèÔ∏è Scene Prompt 3: Ensuring correct breed identification in context of environment

scene\_prompt ="""

You will be provided with a series of images. Your task is to describe the scene based on these sequential images. Stay focused on the animals in the frame.

For each image, your task is to:

1. Identify the animals present in the frame define their colour, breed, and any other notable features. If there are multiple animals present, define the same characteristics for all those in focus.

2. Describe the environment in context of the animals: Provide a brief description of the interaction between the animals and the objects or the environment around them. Be specific about the actions of every animal if there are multiple animals detected in a single frame.

"""

Output:

{
"scene\_story":"A lively dog show takes center stage as two enthusiastic canines race down a carpeted aisle, cheered on by an eager crowd and accompanied by their handlers.",
"images":[
{
"description":"A white and brown Jack Russell Terrier runs energetically on a green carpet, escorted by a woman in a blue jacket. Behind them, a grey poodle closely follows while being guided by another handler in maroon clothing. The carpeted path is bordered by purple barriers adorned with yellow and blue flowers. Spectators and photographers on the left capture the moment."
},
{
"description":"The Jack Russell Terrier continues to lead, bounding forward with its handler. The grey poodle and its handler have gained some ground but maintain their position behind the terrier. The handlers maintain a brisk pace alongside the dogs as the crowd continues to observe and document the event."
},
{
"description":"In the final image, the Jack Russell Terrier keeps its lead, with the grey poodle still following closely. The handlers are encouraging their dogs with focused enthusiasm. The spectators remain engaged, some with cameras ready to capture the exciting finish."
}
]
}

Note: This prompt successfully captured both the specific breeds and the overall scene dynamics, providing a detailed and accurate description. However, the format could be more structured for easier parsing and use in applications. Our final iteration addresses this.

### ‚úèÔ∏è Scene Prompt 4: Structured JSON output with emotional states

scene\_prompt ="""

You will be provided with a series of images from a dog show. Your task is to describe the scene based on these sequential images. Focus on identifying the breeds and describing the key actions.

For each image, your task is to:

1. Identify the animals present in the frame, including their breed, color, and any notable features.

2. Describe the actions of the animals and any interactions with the environment or other animals.

3. Highlight any emotional expressions or notable moments.

Output should be a structured JSON with the following format:

{
"scene\_story": "Brief overview of the scene",
"images": [
{
"frame\_time": "Time of the frame in seconds",
"breeds": [{"breed": "Golden Retriever", "color": "golden"}],
"actions": "Description of the actions and interactions",
"emotion": "Observed emotion or notable moment"
},
...
]
}

"""

Output:

{
"scene\_story":"A dog show competition where handlers are walking their dogs down the green carpeted runway while photographers and spectators watch and take photos.",
"images":[
{
"frame\_time":"0 seconds",
"breeds":[
{"breed":"Wire Fox Terrier","color":"white and tan"},
{"breed":"Standard Poodle","color":"gray"}
],
"actions":"Handlers are walking their dogs down a green carpeted runway. The Wire Fox Terrier on the right is being walked by a handler wearing a dark outfit. A Standard Poodle in the middle is being walked by a handler in a teal blue blazer. Photographers are taking pictures and spectators are observing.",
"emotion":"The Wire Fox Terrier looks attentive and focused."
},
{
"frame\_time":"2 seconds",
"breeds":[
{"breed":"Wire Fox Terrier","color":"white and tan"},
{"breed":"Standard Poodle","color":"gray"}
],
"actions":"The Wire Fox Terrier is still being walked by the handler in a dark outfit. The Standard Poodle is also being walked down the runway, slightly ahead of the Wire Fox Terrier. Both handlers and dogs are making their way to the front end of the runway while onlookers take pictures and watch.",
"emotion":"The dogs are showing a calm and focused demeanor."
}
]
}

Note: This final iteration provides a comprehensive, structured output that's easy to work with programmatically and captures all the key information we set out to extract, including breed identification, actions, and even emotional states.

With a refined prompt in action, we can get some pretty interesting results! Here‚Äôs the result for our initial query: Show me the happiest moments featuring a Golden Retriever

[iframe](https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/d1ff1d4c-14ae-4905-ac56-7efe8e259557.m3u8)

## Conclusion:

Through this experiment, we've demonstrated how iterative prompt engineering can significantly improve the accuracy and detail of video scene indexing. We progressed from basic animal identification to detailed breed recognition, action description, and even emotional state detection. This approach can be adapted to various video processing tasks beyond dog shows, opening up new possibilities in video indexing and search applications.

## Key Takeaways:

Frame-level prompts are excellent for detailed, specific information about individual moments.

Scene-level prompts provide a cohesive narrative and capture actions spanning multiple frames.

Structured outputs (like JSON) make the extracted information more readily usable in downstream applications.

Iterative refinement of prompts is crucial to achieving the desired level of detail and accuracy.

Consider the trade-off between accuracy and computational cost when deciding between frame-level and scene-level analysis.

Use frame-level prompts as a tuning mechanism to inform and improve scene-level prompts.

Look for ways to better integrate frame-level insights into scene-level descriptions for more comprehensive and efficient video indexing.

## Future Directions:

Moving forward, we should explore ways to more effectively bridge the gap between frame-level and scene-level analyses. This could involve developing algorithms that can aggregate frame-level insights to inform scene-level descriptions, or creating more sophisticated prompts that can extract frame-level details while operating at a scene level.

By keeping these considerations in mind, we can continue to refine our approach to video indexing, balancing the need for detailed information with computational efficiency. This balance will be crucial as we scale our solutions to handle larger volumes of video data across diverse use cases.

Remember, the key to effective prompt engineering lies in clearly defining your information needs and iteratively refining your approach based on the outputs.

Happy coding!

## ‚≠êÔ∏è Bonus: Challenges in Prompt Refinement

During our experiment, we encountered challenges in refining our prompts. Two intermediate prompts (originally Scene Prompts 3 and 4) didn't yield the improvements we expected. These challenges highlight the iterative nature of prompt engineering:

1. Over-specification: We found that adding too many specific instructions sometimes led to inconsistent results, with the model focusing on certain aspects while neglecting others.

2. Balancing detail and generalization: Striking the right balance between detailed instructions and allowing the model enough flexibility to generalize was a key challenge.

3. Prompt length: Very long, detailed prompts sometimes resulted in the model losing focus on the primary task.

These challenges underscore the importance of continuous testing and refinement in prompt engineering. Each iteration provides valuable insights, even when the results don't meet expectations. The key is to learn from each attempt and use those insights to guide further refinements.

Remember, the goal of prompt engineering is not just to get the right answer, but to develop a robust, generalizable approach that can handle a wide range of inputs and scenarios.

We would love to see your experiments and hear about your prompting experiences. Join our
[Discord community](https://discord.gg/py9P639jGz)
to share and learn üññ

Want to print your doc?

This is not the way.

Try clicking the ‚ãØ next to your doc name or using a keyboard shortcut (
CtrlP
) instead.

---

